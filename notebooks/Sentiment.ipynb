{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.mft import Mft\n",
    "from checklist.inv_dir import Inv, Dir\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import model_wrapper\n",
    "sentiment = model_wrapper.ModelWrapper()\n",
    "wrapped_pp = PredictorWrapper.wrap_softmax(sentiment.predict_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = checklist.editor.Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "r = csv.DictReader(open('/home/marcotcr/datasets/airline/Tweets.csv'))\n",
    "labels = []\n",
    "confs = []\n",
    "airlines = []\n",
    "tdata = []\n",
    "reasons = []\n",
    "for row in r:\n",
    "    sentiment, conf, airline, text = row['airline_sentiment'], row['airline_sentiment_confidence'], row['airline'], row['text']\n",
    "    labels.append(sentiment)\n",
    "    confs.append(conf)\n",
    "    airlines.append(airline)\n",
    "    tdata.append(text)\n",
    "    reasons.append(row['negativereason'])\n",
    "\n",
    "mapping = {'negative': 0, 'positive': 2, 'neutral': 1}\n",
    "labels = np.array([mapping[x] for x in labels]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tdata\n",
    "parsed_data = list(nlp.pipe(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pp(data):\n",
    "    margin_neutral = 1/3.\n",
    "    mn = margin_neutral / 2.\n",
    "    pr = wrapped_pp(data)[1][:, 1]\n",
    "    pp = np.zeros((pr.shape[0], 3))\n",
    "    neg = pr < 0.5 - mn\n",
    "    pp[neg, 0] = 1 - pr[neg]\n",
    "    pp[neg, 2] = pr[neg]\n",
    "    pos = pr > 0.5 + mn\n",
    "    pp[pos, 0] = 1 - pr[pos]\n",
    "    pp[pos, 2] = pr[pos]\n",
    "    neutral_pos = (pr >= 0.5) * (pr < 0.5 + mn)\n",
    "    pp[neutral_pos, 1] = 1 - (1 / margin_neutral) * np.abs(pr[neutral_pos] - 0.5)\n",
    "    pp[neutral_pos, 2] = 1 - pp[neutral_pos, 1]\n",
    "    neutral_neg = (pr < 0.5) * (pr > 0.5 - mn)\n",
    "    pp[neutral_neg, 1] = 1 - (1 / margin_neutral) * np.abs(pr[neutral_neg] - 0.5)\n",
    "    pp[neutral_neg, 0] = 1 - pp[neutral_neg, 1]\n",
    "    preds = np.argmax(pp, axis=1)\n",
    "    return preds, pp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect: Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_noun = ['flight', 'seat', 'pilot', 'staff', 'service', 'customer service', 'aircraft', 'plane', 'food', 'cabin crew', 'company', 'airline', 'crew']\n",
    "editor.add_lexicon('air_noun', air_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good, great, excellent, amazing, new, terrible, awful, old, interesting, unusual, small, incredible, extraordinary, expensive, important, experimental, bad, awesome, big, ordinary, wonderful, huge, fantastic, American, nice, enormous, exceptional, odd, large, unfamiliar, remarkable, professional, empty, skeleton, easy, open, happy, young, outstanding, exemplary\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('It was {a:bert} {air_noun}.')[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_adj = ['good', 'great', 'excellent', 'amazing', 'extraordinary', 'beautiful', 'fantastic', 'nice', 'incredible', 'exceptional', 'awesome', 'perfect', 'fun', 'happy', 'adorable', 'brilliant', 'exciting', 'sweet', 'wonderful']\n",
    "neg_adj = ['awful', 'bad', 'horrible', 'commercial', 'tough', 'weird', 'aggressive', 'rough', 'lousy', 'unhappy', 'average', 'difficult', 'poor', 'sad', 'frustrating', 'hard', 'lame', 'nasty', 'annoying', 'boring', 'creepy', 'dreadful', 'ridiculous', 'terrible', 'ugly', 'unpleasant']\n",
    "neutral_adj = ['American', 'international', 'British', 'private', 'Italian', 'Indian', 'Australian', 'Israeli', ]\n",
    "editor.add_lexicon('pos_adj', pos_adj, overw)\n",
    "editor.add_lexicon('neg_adj', neg_adj)\n",
    "editor.add_lexicon('neutral_adj', neutral_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editor.tg.unmask('I <mask> the food.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liked, enjoyed, like, appreciate, appreciated, enjoy, loved, love, miss, missed, recommend, wanted, got, needed, likes, prefer, hate, need, admired, want, admire, value, enjoying, enjoys, dislike, dig, use, trust, respect, respected, liking, did, used, get, understand, found, adore, underestimated, preferred, was, valued, feel, have, ,, tried, helped, took, mean, regret, disliked, praised, noticed, dug, hated, loves, had, compliment, remember, cherish, do, rate, about, LOVE, felt, saw, supported, support, applaud, commend, thank, bought, treasure, improved, see, understood, welcome, hit, left, is, beat, all, impressed, know, think, thought, for, believe, thanks, trusted, credit, underestimate, help, take, met, tested, wish, experienced, lost, recommended, blame, owe, leave, in, reviewed, picked, welcomed, made, Love, packed, chose, misses, finished, values, received, delivered, praise, embrace, upgraded, consider, to, changed, worked, into, started, considered, envy, improve, try, fancy, are, follow, drove, experience, sold, meant, respects, needs, compliments, regretted, thanked, rocked, salute, deserved, told, ordered, rode, meet, pleased, surprised, handled, saved, flew, hope, forgive, recruited, complement, brought, hired, loving, doubt, recognize, stressed, just, embraced, survived, crashed, cleaned, spoiled, congratulate, on, choose, notice, watched, favor, remembered, pushed, own, joined, find, owned, earned, cherished, drive, applauded, heard, offer, followed, expanded, deliver, utilize, emphasize, provide, crave, uses, learned, mentioned, ride, filled, gave, moved\n",
      "\n",
      "and, of, love, for, to, ,, like, loved, about, liked, on, found, was, with, left, blame, 's, got, hate, is, get, ing, called, miss, had, ating, remember, have, ., need, took, changed, in, know, :, trust, saw, want, at, are, wanted, see, started, asked, needed, appreciate, appreciated, missed, did, enjoyed\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('I really {bert} the {air_noun}.')[:200]))\n",
    "print()\n",
    "print(', '.join(editor.suggest('I {bert} the {air_noun}.')[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_verb_present = ['like', 'enjoy', 'appreciate', 'love',  'recommend', 'admire', 'value', 'welcome']\n",
    "neg_verb_present = ['hate', 'dislike', 'regret',  'abhor', 'dread', 'despise' ]\n",
    "neutral_verb_present = ['see', 'find']\n",
    "pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
    "neg_verb_past = ['hated', 'disliked', 'regretted',  'abhorred', 'dreaded', 'despised']\n",
    "neutral_verb_past = ['saw', 'found']\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Mft(pos_adj + pos_verb_present + pos_verb_past, labels=2)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 38 examples\n",
      "Test cases:     38\n",
      "Failure rate:   5.3%\n",
      "\n",
      "Example fails:\n",
      "2 (0.8) tough\n",
      "2 (1.0) aggressive\n"
     ]
    }
   ],
   "source": [
    "test = Mft(neg_adj + neg_verb_present + neg_verb_past, labels=0)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 12 examples\n",
      "Test cases:     12\n",
      "Failure rate:   100.0%\n",
      "\n",
      "Example fails:\n",
      "2 (1.0) British\n",
      "2 (1.0) American\n",
      "2 (1.0) found\n"
     ]
    }
   ],
   "source": [
    "test = Mft(neutral_adj + neutral_verb_present + neutral_verb_past, labels=1)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3510, 4992)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editor.template('I {pos_verb_present} {bert} {air_noun}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5616 examples\n",
      "Test cases:     5616\n",
      "Failure rate:   1.8%\n",
      "\n",
      "Example fails:\n",
      "2 (1.0) This was an aggressive airline.\n",
      "2 (1.0) It is an aggressive pilot.\n",
      "2 (1.0) It is a commercial company.\n"
     ]
    }
   ],
   "source": [
    "data = editor.template('{it} {be} {a:pos_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'])\n",
    "data += editor.template('{i} {pos_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'])\n",
    "labels = [2] * len(data)\n",
    "data += editor.template('{i} {neg_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'])\n",
    "data += editor.template('{it} {be} {a:neg_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'])\n",
    "labels += [0] * (len(data) - len(labels))\n",
    "test = Mft(data, labels=labels)\n",
    "# test = Mft(data, labels=2)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 936 examples\n",
      "Test cases:     936\n",
      "Failure rate:   95.1%\n",
      "\n",
      "Example fails:\n",
      "2 (1.0) This is an Israeli seat.\n",
      "2 (1.0) This is an international customer service.\n",
      "0 (0.9) I found the airline.\n"
     ]
    }
   ],
   "source": [
    "data = editor.template('{it} {be} {a:neutral_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'])\n",
    "data += editor.template('{i} {neutral_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'])\n",
    "test = Mft(data, labels=1)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensifiers and reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very , really , absolutely , truly , extremely , quite , most , pretty , incredibly , just , almost , actually , ... , amazingly , especially , exceptionally , surprisingly , unbelievably , equally , utterly , extraordinarily , absolute , overall , otherwise , damn , unusually , obviously , simply , exceedingly , generally , real , a , entirely , overwhelmingly , undeniably , amazing , rather , already , totally , increasingly , altogether , unexpectedly , … , particularly , all , insanely , incredible , fairly , actual , apparently\n"
     ]
    }
   ],
   "source": [
    "print(' , '.join(editor.suggest('{it} {be} {a:bert} {pos_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'])[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "intens_adj = ['very', 'really', 'absolutely', 'truly', 'extremely', 'quite', 'incredibly', 'amazingly', 'especially', 'exceptionally', 'unbelievably', 'utterly', 'exceedingly', 'rather', 'totally', 'particularly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, really, always, also, highly, definitely, all, personally, truly, certainly, actually, absolutely, still, just, thoroughly, very, greatly, especially, particularly, much, we, quite, so, totally, generally, clearly, seriously, never, 'd, genuinely, rather, honestly, do, people, strongly, both, sure, obviously, did, you, fully, REALLY, ly, sincerely, only, most, guys, already, initely, would, completely, deeply, 've, even, Really, and, simply, ,, too, have, they, will, kids, 's, 'll, mostly, can, should, immediately, must, again, extremely, had, ..., now, least, he, dearly, might, to, everyone, fucking, could, kinda, 't, probably, usually, immensely, may, family, hardly, o, does, specifically, many, students, boys, secretly, more, everybody\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('{i} {bert} {pos_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'])[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "intens_verb = [ 'really', 'absolutely', 'truly', 'extremely',  'especially',  'utterly',  'totally', 'particularly', 'highly', 'definitely', 'certainly', 'genuinely', 'honestly', 'strongly', 'sure', 'sincerely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_label = Expect.monotonic(increasing=True, tolerance=0.1)\n",
    "non_neutral_pred = lambda pred, *args, **kwargs: pred != 1\n",
    "monotonic_label = Expect.slice_pairwise(monotonic_label, non_neutral_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 4000 examples\n",
      "Test cases:      2000\n",
      "After filtering: 1996 (99.8%)\n",
      "Fails (rate):    26 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0 (1.0) This is a commercial plane.\n",
      "2 (1.0) This is an exceedingly commercial plane.\n",
      "\n",
      "0 (0.9) It is a commercial aircraft.\n",
      "2 (1.0) It is a really commercial aircraft.\n",
      "\n",
      "0 (1.0) This was a creepy seat.\n",
      "2 (1.0) This was an amazingly creepy seat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = editor.template(['{it} {be} {a:pos_adj} {air_noun}.', '{it} {be} {a:intens} {pos_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500)\n",
    "data += editor.template(['{i} {pos_verb} {the} {air_noun}.', '{i} {intens} {pos_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500)\n",
    "data += editor.template(['{it} {be} {a:neg_adj} {air_noun}.', '{it} {be} {a:intens} {neg_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500)\n",
    "data += editor.template(['{i} {neg_verb} {the} {air_noun}.', '{i} {intens} {neg_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500)\n",
    "test = Dir(data, monotonic_label)\n",
    "test.run(new_pp)\n",
    "test.set_monotonic_print(increasing=True)\n",
    "test.summary(3)\n",
    "# test = Mft(data, labels=labels)\n",
    "# test = Mft(data, labels=2)\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_adj = ['somewhat', 'kinda', 'mostly', 'probably', 'generally', 'reasonably', 'little', 'bit', 'slightly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_label_down = Expect.monotonic(increasing=False, tolerance=0.1)\n",
    "monotonic_label_down = Expect.slice_pairwise(monotonic_label_down, non_neutral_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 4000 examples\n",
      "Test cases:     2000\n",
      "Cases filtered out: 1987 (99.3%)\n",
      "Failure rate:   30.8%\n",
      "\n",
      "Example fails:\n",
      "0 (0.9) It was an average plane.\n",
      "0 (1.0) It was a kinda average plane.\n",
      "\n",
      "0 (0.9) It is an average flight.\n",
      "0 (1.0) It is a probably average flight.\n",
      "\n",
      "0 (0.9) It is a creepy food.\n",
      "0 (1.0) It is a probably creepy food.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = editor.template(['{it} {be} {a:pos_adj} {air_noun}.', '{it} {be} {a:red} {pos_adj} {air_noun}.'] , red=reducer_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=1000)\n",
    "data += editor.template(['{it} {be} {a:neg_adj} {air_noun}.', '{it} {be} {a:red} {neg_adj} {air_noun}.'] , red=reducer_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=1000)\n",
    "test = Dir(data, monotonic_label_down)\n",
    "test.run(new_pp)\n",
    "test.set_monotonic_print(increasing=False)\n",
    "test.summary(3)\n",
    "# test = Mft(data, labels=labels)\n",
    "# test = Mft(data, labels=2)\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invariance: change neutral words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = set(\n",
    "    ['.', 'the', 'The', ',', 'a', 'A', 'and', 'of', 'to', 'it', 'that', 'in',\n",
    "     'this', 'for',  'you', 'there', 'or', 'an', 'by', 'about', 'flight', 'my',\n",
    "     'in', 'of', 'have', 'with', 'was', 'at', 'it', 'get', 'from', 'this', 'Flight', 'plane'\n",
    "    ])\n",
    "forbidden = set(['No', 'no', 'Not', 'not', 'Nothing', 'nothing', 'without'] + pos_adj + neg_adj + pos_verb_present + pos_verb_past + neg_verb_present + neg_verb_past)\n",
    "def change_neutral(d):\n",
    "#     return d.text\n",
    "    examples = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        examples.extend([x[1] for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return [examples[i] for i in idxs]\n",
    "# Perturb.perturb(parsed_data[:5], perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Perturb.perturb(sentences, change_neutral, nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5009 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    64 (12.8%)\n",
      "\n",
      "Example fails:\n",
      "0 (1.0) @SouthwestAir how do I get a companion pass\n",
      "1 (0.9) @SouthwestAir how do I add a companion pass\n",
      "\n",
      "2 (0.9) @united well perhaps you could highlight where that is stated.  We travel between Canada &amp; USA on United with only Nexus\n",
      "1 (0.8) @united well perhaps they could highlight where that is stated.  We travel between Canada &amp; USA on United with only Nexus\n",
      "1 (0.9) @united well perhaps someone could highlight where that is stated.  We travel between Canada &amp; USA on United with only Nexus\n",
      "\n",
      "2 (0.9) @JetBlue sadly, no! I have the app, but it also is experiencing difficulties. The flight information boards are keeping me updated.\n",
      "0 (0.7) @JetBlue sadly, no! I checked the app, but it also is experiencing difficulties. The flight information boards are keeping me updated.\n",
      "0 (0.7) @JetBlue sadly, no! I have the app, but it also is experiencing difficulties. The airline information boards are keeping me updated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add negative phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = editor.template('I {pos_verb_present} you.')\n",
    "positive += editor.template('You are {pos_adj}.')\n",
    "positive += ['I would fly with you again.']\n",
    "positive.remove('You are happy.')\n",
    "negative = editor.template('I {neg_verb_present} you.')\n",
    "negative += editor.template('You are {neg_adj}.')\n",
    "negative += ['Never flying with you again.']\n",
    "def add_phrase_function(phrases):\n",
    "    def pert(d):\n",
    "        while d[-1].pos_ == 'PUNCT':\n",
    "            d = d[:-1]\n",
    "        d = d.text\n",
    "        ret = [d + '. ' + x for x in phrases]\n",
    "        idx = np.random.choice(len(ret), 10, replace=False)\n",
    "        ret = [ret[i] for i in idx]\n",
    "        return ret\n",
    "    return pert\n",
    "\n",
    "# perturbed = PerturbFactory.perturb_key(small, 'sentence', add_phrase_function(positive))\n",
    "# test = mltest.Test(perturbed, expectation_fn = mon_increasing)\n",
    "# r = test.run(model.predict_and_confidence, is_binary=False, n=500)\n",
    "# r.summary(5, format_fn=format_perturb_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_1 = Expect.monotonic(label=2, increasing=True, tolerance=0.1)\n",
    "monotonic_1_down = Expect.monotonic(label=2, increasing=False, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5500 examples\n",
      "Test cases:      500\n",
      "After filtering: 150 (30.0%)\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, add_phrase_function(positive), nsamples=500)\n",
    "test = Dir(data, monotonic_1)\n",
    "test.run(new_pp, overwrite=True)\n",
    "test.set_monotonic_print(label=2, increasing=True)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5500 examples\n",
      "Test cases:      500\n",
      "After filtering: 370 (74.0%)\n",
      "Fails (rate):    83 (22.4%)\n",
      "\n",
      "Example fails:\n",
      "0 (0.8) @USAirways Nice try.  Doesn't apply to Philly.\n",
      "2 (1.0) @USAirways Nice try.  Doesn't apply to Philly. You are tough.\n",
      "0 (0.8) @USAirways Nice try.  Doesn't apply to Philly. You are aggressive.\n",
      "\n",
      "0 (0.8) @united maybe one day you'll be the one quoted on http://t.co/mJkpgVXmPC\n",
      "2 (1.0) @united maybe one day you'll be the one quoted on http://t.co/mJkpgVXmPC. You are aggressive.\n",
      "\n",
      "0 (1.0) @SouthwestAir schedule is open through the end of October, got Columbus day wknd in New England for ~50K points for 4! Check your calendar!\n",
      "2 (0.9) @SouthwestAir schedule is open through the end of October, got Columbus day wknd in New England for ~50K points for 4! Check your calendar. You are aggressive.\n",
      "0 (1.0) @SouthwestAir schedule is open through the end of October, got Columbus day wknd in New England for ~50K points for 4! Check your calendar. You are tough.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, add_phrase_function(negative), nsamples=500)\n",
    "test = Dir(data, monotonic_1_down)\n",
    "test.run(new_pp, overwrite=True)\n",
    "test.set_monotonic_print(label=2, increasing=False)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect: robustness\n",
    "### Invariance: adding irrelevant stuff before and after.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def random_string(n):\n",
    "    return ''.join(np.random.choice([x for x in string.ascii_letters + string.digits], n))\n",
    "def random_url(n=6):\n",
    "    return 'https://t.co/%s' % random_string(n)\n",
    "def random_handle(n=6):\n",
    "    return '@%s' % random_string(n)\n",
    "\n",
    "# data['sentence']\n",
    "\n",
    "def add_irrelevant(sentence):\n",
    "    urls_and_handles = [random_url(n=6) for _ in range(5)] + [random_handle() for _ in range(5)]\n",
    "    irrelevant_before = ['@airline '] + urls_and_handles\n",
    "    irrelevant_after = urls_and_handles \n",
    "    rets = ['%s %s' % (x, sentence) for x in irrelevant_before ]\n",
    "    rets += ['%s %s' % (sentence, x) for x in irrelevant_after]\n",
    "    return rets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 11000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    56 (11.2%)\n",
      "\n",
      "Example fails:\n",
      "0 (0.9) @united well. As of yet, our checked bag has already vanished and we haven't left the airport yet.\n",
      "2 (0.7) @united well. As of yet, our checked bag has already vanished and we haven't left the airport yet. @lUVsAS\n",
      "2 (0.9) @united well. As of yet, our checked bag has already vanished and we haven't left the airport yet. @N6GErs\n",
      "\n",
      "1 (0.7) @JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Daily Journal http://t.co/9bzqZQx8DC\n",
      "2 (0.8) @airline  @JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Daily Journal http://t.co/9bzqZQx8DC\n",
      "0 (1.0) https://t.co/Y7VByc @JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Daily Journal http://t.co/9bzqZQx8DC\n",
      "\n",
      "2 (1.0) @AmericanAir come on I just want to go home I can't miss another day of work #stuckinmemphis #texasisclosed\n",
      "1 (0.5) @LwpRRX @AmericanAir come on I just want to go home I can't miss another day of work #stuckinmemphis #texasisclosed\n",
      "1 (0.6) @kxE3XI @AmericanAir come on I just want to go home I can't miss another day of work #stuckinmemphis #texasisclosed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(sentences, add_irrelevant, nsamples=500)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### punctuation, contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1162 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    15 (3.0%)\n",
      "\n",
      "Example fails:\n",
      "2 (0.7) @SouthwestAir F5R3ZZ\n",
      "0 (0.8) @SouthwestAir F5R3ZZ.\n",
      "\n",
      "0 (0.8) @USAirways it still says that I can't check into my flight because the information is incorrect but everything is entered correctly\n",
      "1 (0.6) @USAirways it still says that I can't check into my flight because the information is incorrect but everything is entered correctly.\n",
      "\n",
      "0 (0.9) @usairways I get extended hold times due to the weather...but 2-1/2 hours on hold (and counting). HELP!!\n",
      "2 (0.8) @usairways I get extended hold times due to the weather...but 2-1/2 hours on hold (and counting). HELP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, Perturb.punctuation, nsamples=500)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2087 examples\n",
      "Test cases:      1000\n",
      "Fails (rate):    29 (2.9%)\n",
      "\n",
      "Example fails:\n",
      "2 (0.7) @SouthwestAir    How's life @ the NOC?\n",
      "0 (0.9) @SouthwestAir    How is life @ the NOC?\n",
      "\n",
      "2 (0.9) @AmericanAir it's flight 5348\n",
      "1 (0.6) @AmericanAir it is flight 5348\n",
      "\n",
      "1 (0.9) @USAirways any update on this flight?It's more than three hours delayed. Thank you.\n",
      "2 (0.7) @USAirways any update on this flight?It is more than three hours delayed. Thank you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(sentences, Perturb.contractions, nsamples=1000)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect: temporal awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate', 'dislike', 'regret', 'abhor', 'dread', 'despise']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.template('{neg_verb_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 8000 examples\n",
      "Test cases:      8000\n",
      "Fails (rate):    1531 (19.1%)\n",
      "\n",
      "Example fails:\n",
      "0 (0.9) I think this airline is great, but I used to think it was difficult.\n",
      "2 (1.0) I abhor this airline, but in the past I would love it.\n",
      "2 (1.0) I used to admire this airline, even though now I despise it.\n"
     ]
    }
   ],
   "source": [
    "change = ['but', 'even though', 'although', '']\n",
    "data = editor.template(['I used to think this airline was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this airline is {pos_adj}, {change} I used to think it was {neg_adj}.',\n",
    "                                 'In the past I thought this airline was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this airline is {pos_adj}, {change} in the past I thought it was {neg_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, nsamples=500)\n",
    "data += editor.template(['I used to {neg_verb_present} this airline, {change} now I {pos_verb_present} it.',\n",
    "                                 'I {pos_verb_present} this airline, {change} I used to {neg_verb_present} it.',\n",
    "                                 'In the past I would {neg_verb_present} this airline, {change} now I {pos_verb} it.',\n",
    "                                 'I {pos_verb_present} this airline, {change} in the past I would {neg_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, nsamples=500)\n",
    "labels = [2] * len(data)\n",
    "\n",
    "data += editor.template(['I used to think this airline was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this airline is {neg_adj}, {change} I used to think it was {pos_adj}.',\n",
    "                                 'In the past I thought this airline was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this airline is {neg_adj}, {change} in the past I thought it was {pos_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, nsamples=500)\n",
    "data += editor.template(['I used to {pos_verb_present} this airline, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this airline, {change} I used to {pos_verb_present} it.',\n",
    "                                 'In the past I would {pos_verb_present} this airline, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this airline, {change} in the past I would {pos_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, nsamples=500)\n",
    "labels += [0] * (len(data) - len(labels))\n",
    "test = Mft(data, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used to should reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 9204 examples\n",
      "Test cases:      4602\n",
      "After filtering: 27 (0.6%)\n",
      "Fails (rate):    14 (51.9%)\n",
      "\n",
      "Example fails:\n",
      "0 (0.8) this was a commercial flight.\n",
      "0 (1.0) I used to think this was a commercial flight.\n",
      "\n",
      "0 (0.9) it is an average food.\n",
      "0 (1.0) I used to think it is an average food.\n",
      "\n",
      "0 (0.9) that was a commercial company.\n",
      "0 (1.0) I used to think that was a commercial company.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = editor.template(['{it} {be} {a:adj} {air_noun}.', 'I used to think {it} {be} {a:adj} {air_noun}.'], it=['it', 'this', 'that'], be=['is', 'was'], adj=editor.lexicons['pos_adj'] + editor.lexicons['neg_adj'])\n",
    "data += editor.template(['{i} {verb} {the} {air_noun}.', '{i} used to {verb} {the} {air_noun}.'], i=['I', 'We'], the=['this', 'that', 'the'], verb=editor.lexicons['pos_verb_present'] + editor.lexicons['neg_verb_present'])\n",
    "test = Dir(data, monotonic_label_down)\n",
    "# test = Mft(data, labels=2)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Perturb.perturb(parsed_data, Perturb.change_names, nsamples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3641 examples\n",
      "Test cases:      331\n",
      "Fails (rate):    25 (7.6%)\n",
      "\n",
      "Example fails:\n",
      "0 (0.8) @USAirways owes Tammy from the Winston-Salem call center for keeping me as a customer!\n",
      "2 (0.8) @USAirways owes Chelsea from the Winston-Salem call center for keeping me as a customer!\n",
      "2 (0.8) @USAirways owes Hannah from the Winston-Salem call center for keeping me as a customer!\n",
      "\n",
      "0 (0.9) @united Hey so many time changes for UA 1534. We going tonight or what? MIA - EWR\n",
      "2 (0.7) @united Hey so many time changes for UA 1534. We going tonight or what? Amanda Green\n",
      "1 (0.8) @united Hey so many time changes for UA 1534. We going tonight or what? Stephanie Robinson\n",
      "\n",
      "2 (0.9) @JetBlue your employee Charles cave at the gate at MSY went above and beyond to help try to help me find my glasses. Thought u should know\n",
      "0 (0.9) @JetBlue your employee Jesus cave at the gate at MSY went above and beyond to help try to help me find my glasses. Thought u should know\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, Perturb.change_names, nsamples=1000)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 9999 examples\n",
      "Test cases:      909\n",
      "Fails (rate):    61 (6.7%)\n",
      "\n",
      "Example fails:\n",
      "2 (0.7) @USAirways us2118\n",
      "My wife in Boston says no snow right now.\n",
      "1 (0.6) @USAirways us2118\n",
      "My wife in Greenville says no snow right now.\n",
      "0 (0.8) @USAirways us2118\n",
      "My wife in Park Ridge says no snow right now.\n",
      "\n",
      "1 (0.5) @SouthwestAir to start daily #B737-700 flights from #Columbus OH to #Oakland on 8AUG #avgeek\n",
      "0 (0.7) @SouthwestAir to start daily #B737-700 flights from #Columbus OH to #Warner Robins on 8AUG #avgeek\n",
      "0 (0.7) @SouthwestAir to start daily #B737-700 flights from #Columbus OH to #Richmond on 8AUG #avgeek\n",
      "\n",
      "2 (0.9) @SouthwestAir we have to stay in Chicago overnight and meet up with our bags there. I hope they stay put and don't get put on a flight.\n",
      "1 (0.5) @SouthwestAir we have to stay in Cranston overnight and meet up with our bags there. I hope they stay put and don't get put on a flight.\n",
      "1 (0.7) @SouthwestAir we have to stay in Dunwoody overnight and meet up with our bags there. I hope they stay put and don't get put on a flight.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, Perturb.change_location, nsamples=1000)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 11000 examples\n",
      "Test cases:      1000\n",
      "Fails (rate):    21 (2.1%)\n",
      "\n",
      "Example fails:\n",
      "1 (0.9) @americanair the best is your 800 message saying to use website and your website is saying you need to call.  If you don't answer, #hardtodo\n",
      "2 (0.9) @americanair the best is your 704 message saying to use website and your website is saying you need to call.  If you don't answer, #hardtodo\n",
      "2 (1.0) @americanair the best is your 670 message saying to use website and your website is saying you need to call.  If you don't answer, #hardtodo\n",
      "\n",
      "0 (0.9) @VirginAmerica save some for 871 tomorrow AM!\n",
      "1 (0.6) @VirginAmerica save some for 826 tomorrow AM!\n",
      "\n",
      "0 (0.7) @USAirways   my miles will expire on 2/29 and it could take someone 10 days to respond...I have over 150000 miles that I do not lose i❤usair\n",
      "1 (0.6) @USAirways   my miles will expire on 2/29 and it could take someone 10 days to respond...I have over 134350 miles that I do not lose i❤usair\n",
      "1 (0.6) @USAirways   my miles will expire on 2/29 and it could take someone 10 days to respond...I have over 178595 miles that I do not lose i❤usair\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Perturb.perturb(parsed_data, Perturb.change_number, nsamples=1000)\n",
    "test = Inv(data)\n",
    "test.run(new_pp)\n",
    "test.summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect:fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
