{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_suite import TestSuite\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import bert_squad_model\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "model = bert_squad_model.BertSquad()\n",
    "invert = lambda a: model.predict_pairs([(x[1], x[0]) for x in a])\n",
    "new_pp = PredictorWrapper.wrap_predict(invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd01bd47b35479a969434f296e142d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['John']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_pairs([('Who is smarter?', 'John is smart')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<checklist.text_generation.TextGenerator at 0x7f6ce1458fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = checklist.editor.Editor()\n",
    "editor.tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad_with_context(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'C: %s\\nQ: %s\\n' % (c, q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'Q: %s\\n' % (q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_squad(fold='validation'):\n",
    "    answers = []\n",
    "    data = []\n",
    "    ids = []\n",
    "    files = {\n",
    "        'validation': '/home/marcotcr/datasets/squad/dev-v1.1.json',\n",
    "        'train': '/home/marcotcr//datasets/squad/train-v1.1.json',\n",
    "        }\n",
    "    f = json.load(open(files[fold]))\n",
    "    for t in f['data']:\n",
    "        for p in t['paragraphs']:\n",
    "            context = p['context']\n",
    "            for qa in p['qas']:\n",
    "                data.append({'passage': context, 'question': qa['question'], 'id': qa['id']})\n",
    "                answers.append(set([(x['text'], x['answer_start']) for x in qa['answers']]))\n",
    "    return data, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data, answers =  load_squad()\n",
    "spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_squad.pkl', 'rb'))\n",
    "pairs = [(x['passage'], x['question']) for x in data]\n",
    "processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better, older, taller, younger, smarter, worse, different, bigger, more, stronger, shorter, less, faster, smaller, tougher, larger, wiser, richer, other, cooler, nicer, darker, greater, happier, hotter, longer, higher, weaker, heavier, slower, harder, closer, lower, quicker, safer, thinner, healthier, easier, lighter, wealthier, cheaper, thicker, quieter, brighter, colder, louder, stranger, deeper, cleaner, poorer, simpler, newer, sharper, warmer, wider, superior, lesser, smoother, earlier, farther\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('{first_name} is {mask} than {first_name2}.')[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tall', 'tall')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Patrick is darker than Emily.', 'Who is less dark?'),\n",
       "  ('Patrick is darker than Emily.', 'Who is dark?')],\n",
       " ['Emily', 'Patrick'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[0], t.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    ),(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name1}','{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    save=True\n",
    "    )\n",
    "test = MFT(**t)\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'A is shorter / weaker / etc than B. Who is less short / weak / etc? B', 'Vocabulary', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossproduct(t):\n",
    "    # takes the output of editor.template and does the cross product of contexts and qas\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "    for x in t.data:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    t.data = ret\n",
    "    t.labels = ret_labels\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))#list(set(comp_pairs + [(x[1], x[0]) for x in comp_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    save=True\n",
    "    ))\n",
    "test = MFT(**t)\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'A is shorter / weaker / etc than B. Who is OPPOSITE (taller, stronger ,etc)? B', 'Vocabulary', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very, pretty, extremely, quite, also, still, more, really, not, fairly, incredibly, rather, now, generally, already, clearly, relatively, highly, particularly, so, surprisingly, most, currently, certainly, super, definitely, increasingly, being, especially, understandably\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "print(', '.join(editor.suggest('John is {mask} {state} about the project.', state=state)[:30]))\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2352 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7978f35e820341aea49378e65f56dde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=294.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      196\n",
      "Fails (rate):    177 (90.3%)\n",
      "\n",
      "Example fails:\n",
      "C: Sean is passionate about the project. Taylor is extremely passionate about the project.\n",
      "Q: Who is least passionate about the project?\n",
      "A: Sean\n",
      "P: Taylor\n",
      "\n",
      "\n",
      "----\n",
      "C: Joseph is vocal about the project. Anna is extremely vocal about the project.\n",
      "Q: Who is least vocal about the project?\n",
      "A: Joseph\n",
      "P: Anna\n",
      "\n",
      "\n",
      "----\n",
      "C: Kyle is serious about the project. Michelle is quite serious about the project.\n",
      "Q: Who is least serious about the project?\n",
      "A: Kyle\n",
      "P: Michelle\n",
      "\n",
      "C: Michelle is quite serious about the project. Kyle is slightly serious about the project.\n",
      "Q: Who is most serious about the project?\n",
      "A: Michelle\n",
      "P: Kyle\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    save=True\n",
    "    ))\n",
    "test = MFT(**t)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?', 'Vocabulary', 'TODO: DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, chape, color, age, material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couch, sofa, wall, carpet, chair, table, light, door, clock, lamp, mirror, bed, TV, bar, window, tree, box, desk, painting, fridge, curtain, screen, fan, camera, frame, wallpaper, rug, cabinet, elephant, television\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('There is {a:p.v1} {p.v2} {mask} in the room.', p=props, verbose=False)[:30]))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    save=True\n",
    "    ))\n",
    "test = MFT(**t)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'size, shape, age, color', 'Taxonomy', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b1ac54f25a47c5bd127787c9734053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    58 (58.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Christopher is a Chinese escort.\n",
      "Q: What is Christopher's job?\n",
      "A: escort\n",
      "P: Chinese escort\n",
      "\n",
      "\n",
      "----\n",
      "C: Noah is a Russian photographer.\n",
      "Q: What is Noah's job?\n",
      "A: photographer\n",
      "P: Russian photographer\n",
      "\n",
      "\n",
      "----\n",
      "C: Danielle is a Japanese economist.\n",
      "Q: What is Danielle's job?\n",
      "A: economist\n",
      "P: Japanese economist\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    save=True,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Profession vs nationality', 'Taxonomy', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal vs vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 400 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ee11f868914bf0b840918624b5e9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    24 (24.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Jessica has a rabbit and a train.\n",
      "Q: What vehicle does Jessica have?\n",
      "A: train\n",
      "P: a rabbit and a train\n",
      "\n",
      "C: Jessica has a train and a rabbit.\n",
      "Q: What vehicle does Jessica have?\n",
      "A: train\n",
      "P: a train and a rabbit\n",
      "\n",
      "\n",
      "----\n",
      "C: Matthew has a bull and a van.\n",
      "Q: What vehicle does Matthew have?\n",
      "A: van\n",
      "P: a bull and a van\n",
      "\n",
      "C: Matthew has a van and a bull.\n",
      "Q: What vehicle does Matthew have?\n",
      "A: van\n",
      "P: a van and a bull\n",
      "\n",
      "\n",
      "----\n",
      "C: Jordan has a duck and a tractor.\n",
      "Q: What vehicle does Jordan have?\n",
      "A: tractor\n",
      "P: a duck and a tractor\n",
      "\n",
      "C: Jordan has a tractor and a duck.\n",
      "Q: What vehicle does Jordan have?\n",
      "A: tractor\n",
      "P: a tractor and a duck\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    save=True\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Animal vs Vehicle', 'Taxonomy', 'TODO: DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 600 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b758290c64019a5774696c320dcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=78.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      300\n",
      "Fails (rate):    33 (11.0%)\n",
      "\n",
      "Example fails:\n",
      "Q: What is the general perception of non-Mongolian histories of Genghis Khan by Mongolians themselves?\n",
      "P: unfairly biased\n",
      "\n",
      "Q: What is the general perception of nonM-ongolian histories of Genghis Khan by Mongolians themselves?\n",
      "P: unfairly biased against Genghis Khan\n",
      "\n",
      "\n",
      "----\n",
      "Q: What was the reason the Italian Constitutional court gave that resulted in Mr. Costa losing his his claim against ENEL?\n",
      "P: the nationalisation law was from 1962\n",
      "\n",
      "Q: What was the reason the Italian Constitutional court gave that resulted in Mr. Cost alosing his his claim against ENEL?\n",
      "P: because the nationalisation law was from 1962\n",
      "\n",
      "\n",
      "----\n",
      "Q: On what did Luther's friend blame his sadness and entrance into the cloister?\n",
      "P: the deaths of two friends\n",
      "\n",
      "Q: On what did Luther' sfriend blame his sadness and entrance into the cloister?\n",
      "P: deaths of two friends\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def question_typo(x):\n",
    "    return (x[0], Perturb.add_typos(x[1]))\n",
    "t = Perturb.perturb(pairs, question_typo, nsamples=300)\n",
    "test = INV(**t)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)\n",
    "suite.add(test, 'Question typo', 'Robustness', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 605 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dac3438a4c04022b259052733d9042e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      300\n",
      "Fails (rate):    16 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "Q: What is in Eldon Square?\n",
      "P: all but one side of the original Eldon Square itself\n",
      "\n",
      "Q: What's in Eldon Square?\n",
      "P: all but one side of the original Eldon Square\n",
      "\n",
      "\n",
      "----\n",
      "Q: How did the black death make it to the Mediterranean and Europe?\n",
      "P: travelled along the Silk Road\n",
      "\n",
      "Q: How'd the black death make it to the Mediterranean and Europe?\n",
      "P: Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60% of Europe's total population\n",
      "\n",
      "\n",
      "----\n",
      "Q: What is the name of contemporary Mongolian currency?\n",
      "P: tögrög\n",
      "\n",
      "Q: What's the name of contemporary Mongolian currency?\n",
      "P: Mongolian tögrög\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def contractions(x):\n",
    "    conts = Perturb.contractions(x[1])\n",
    "    return [(x[0], a) for a in conts]\n",
    "t = Perturb.perturb(pairs, contractions, nsamples=300)\n",
    "test = INV(**t)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)\n",
    "suite.add(test, 'Contractions', 'Robustness', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = set()\n",
    "for x, _ in processed_pairs:\n",
    "    for y in x.sents:\n",
    "        random_sentences.add(y.text)\n",
    "random_sentences = list(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 900 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf9d9f492d4d8886edf8a7fb4ad5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      300\n",
      "Fails (rate):    24 (8.0%)\n",
      "\n",
      "Example fails:\n",
      "Q: How many tree species are in the rainforest?\n",
      "P: 16,000\n",
      "\n",
      "Q: How many tree species are in the rainforest?\n",
      "P: 1,100\n",
      "Perturb: add to end: Westminster MPs are unable to vote on the domestic legislation of the Scottish Parliament. \n",
      "\n",
      "\n",
      "----\n",
      "Q: What was renumbered in Newcastle upon completion of the Western Bypass?\n",
      "P: the roads between this and the A1's former alignment through the Tyne Tunnel were renumbered\n",
      "\n",
      "Q: What was renumbered in Newcastle upon completion of the Western Bypass?\n",
      "P: the roads\n",
      "Perturb: add to beg: In addition to arguing that the rat population was insufficient to account for a bubonic plague pandemic, sceptics of the bubonic plague theory point out that the symptoms of the Black Death are not unique (and arguably in some accounts may differ from bubonic plague); that transference via fleas in goods was likely to be of marginal significance; and that the DNA results may be flawed and might not have been repeated elsewhere, despite extensive samples from other mass graves. \n",
      "\n",
      "\n",
      "----\n",
      "Q: Where did Tesla begin working in 1884?\n",
      "P: Edison Machine Works\n",
      "\n",
      "Q: Where did Tesla begin working in 1884?\n",
      "P: New York City:57–60 where he was hired by Thomas Edison to work at his Edison Machine Works\n",
      "Perturb: add to end: This is not a problem except for patients on mechanical ventilators, since gas supplied through oxygen masks in medical applications is typically composed of only 30%–50% O\n",
      "2 by volume (about 30 kPa at standard pressure). \n",
      "\n",
      "Q: Where did Tesla begin working in 1884?\n",
      "P: New York City:57–60 where he was hired by Thomas Edison to work at his Edison Machine Works\n",
      "Perturb: add to beg: This is not a problem except for patients on mechanical ventilators, since gas supplied through oxygen masks in medical applications is typically composed of only 30%–50% O\n",
      "2 by volume (about 30 kPa at standard pressure). \n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def add_random_sentence(x, **kwargs):\n",
    "    random_s = np.random.choice(random_sentences)\n",
    "    while random_s in x[0]:\n",
    "        random_s = np.random.choice(random_sentences)\n",
    "    random_s = random_s.strip('.') + '. '\n",
    "    meta = ['add to end: %s' % random_s, 'add to beg: %s' % random_s]\n",
    "    return [(x[0] + random_s, x[1]), (random_s + x[0], x[1])], meta\n",
    "\n",
    "def format_add(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "t = Perturb.perturb(pairs, add_random_sentence, nsamples=300, returns_meta=True)\n",
    "test = INV(**t)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_add)\n",
    "suite.add(test, 'Add a random sentence to context', 'Robustness', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 186 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23b57f699724d59b07aa9310e3d7158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      93\n",
      "Fails (rate):    48 (51.6%)\n",
      "\n",
      "Example fails:\n",
      "C: Both Melissa and Rebecca were nurses, but there was a change in Rebecca, who is now an economist.\n",
      "Q: Who is an economist?\n",
      "A: Rebecca\n",
      "P: Rebecca were nurses, but there was a change in Rebecca\n",
      "\n",
      "\n",
      "----\n",
      "C: Both Amy and Amanda were educators, but there was a change in Amanda, who is now an actor.\n",
      "Q: Who is an actor?\n",
      "A: Amanda\n",
      "P: Amanda were educators, but there was a change in Amanda\n",
      "\n",
      "\n",
      "----\n",
      "C: Both Madison and James were investigators, but there was a change in James, who is now a photographer.\n",
      "Q: Who is a photographer?\n",
      "A: James\n",
      "P: James were investigators, but there was a change in James\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'There was a change in profession', 'Temporal', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 400 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7973c9506ac1413d904f624e930167d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    85 (85.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Danielle became a accountant before Kevin did.\n",
      "Q: Who became a accountant last?\n",
      "A: Kevin\n",
      "P: Danielle\n",
      "\n",
      "C: Kevin became a accountant after Danielle did.\n",
      "Q: Who became a accountant first?\n",
      "A: Danielle\n",
      "P: Kevin\n",
      "\n",
      "C: Kevin became a accountant after Danielle did.\n",
      "Q: Who became a accountant last?\n",
      "A: Kevin\n",
      "P: Kevin became a accountant after Danielle\n",
      "\n",
      "\n",
      "----\n",
      "C: Kelly became a executive before Maria did.\n",
      "Q: Who became a executive last?\n",
      "A: Maria\n",
      "P: Kelly\n",
      "\n",
      "C: Maria became a executive after Kelly did.\n",
      "Q: Who became a executive first?\n",
      "A: Kelly\n",
      "P: Maria\n",
      "\n",
      "\n",
      "----\n",
      "C: Amanda became a interpreter before Maria did.\n",
      "Q: Who became a interpreter last?\n",
      "A: Maria\n",
      "P: Amanda\n",
      "\n",
      "C: Maria became a interpreter after Amanda did.\n",
      "Q: Who became a interpreter last?\n",
      "A: Maria\n",
      "P: Amanda\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Understanding before / after / first / last', 'Temporal', 'TODO: DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 796 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a738044be89d4116a1180cdba06f6e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      199\n",
      "Fails (rate):    141 (70.9%)\n",
      "\n",
      "Example fails:\n",
      "C: Sarah is not an educator. Robert is.\n",
      "Q: Who is an educator?\n",
      "A: Robert\n",
      "P: Sarah\n",
      "\n",
      "C: Robert is an educator. Sarah is not.\n",
      "Q: Who is not an educator?\n",
      "A: Sarah\n",
      "P: Robert\n",
      "\n",
      "\n",
      "----\n",
      "C: Thomas is not an editor. Anna is.\n",
      "Q: Who is an editor?\n",
      "A: Anna\n",
      "P: Thomas\n",
      "\n",
      "\n",
      "----\n",
      "C: Daniel is not an organizer. Emma is.\n",
      "Q: Who is an organizer?\n",
      "A: Emma\n",
      "P: Daniel\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Negation in context, may or may not be in question', 'Negation', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 776 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bb507133bb4857a378b39e528b33ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      97\n",
      "Fails (rate):    97 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Patrick is an author. Victoria is a historian.\n",
      "Q: Who is not an author?\n",
      "A: Victoria\n",
      "P: Patrick\n",
      "\n",
      "C: Patrick is an author. Victoria is a historian.\n",
      "Q: Who is not a historian?\n",
      "A: Patrick\n",
      "P: Victoria\n",
      "\n",
      "C: Victoria is a historian. Patrick is an author.\n",
      "Q: Who is not an author?\n",
      "A: Victoria\n",
      "P: Patrick\n",
      "\n",
      "\n",
      "----\n",
      "C: Austin is an artist. Benjamin is an escort.\n",
      "Q: Who is not an artist?\n",
      "A: Benjamin\n",
      "P: Austin\n",
      "\n",
      "C: Austin is an artist. Benjamin is an escort.\n",
      "Q: Who is not an escort?\n",
      "A: Austin\n",
      "P: Benjamin\n",
      "\n",
      "C: Benjamin is an escort. Austin is an artist.\n",
      "Q: Who is not an artist?\n",
      "A: Benjamin\n",
      "P: Austin\n",
      "\n",
      "\n",
      "----\n",
      "C: Patrick is an investor. Zachary is a nurse.\n",
      "Q: Who is not a nurse?\n",
      "A: Patrick\n",
      "P: Zachary\n",
      "\n",
      "C: Zachary is a nurse. Patrick is an investor.\n",
      "Q: Who is not an investor?\n",
      "A: Zachary\n",
      "P: Patrick\n",
      "\n",
      "C: Zachary is a nurse. Patrick is an investor.\n",
      "Q: Who is not a nurse?\n",
      "A: Patrick\n",
      "P: Zachary\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Negation in question only', 'Negation', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness spinoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profession    fail_men fail_women (count)\n",
      "employee        0.20      0.90     (315)\n",
      "accountant      0.01      0.82     (318)\n",
      "attorney        0.02      0.76     (304)\n",
      "actor           0.00      0.74     (300)\n",
      "architect       0.00      0.73     (274)\n",
      "academic        0.03      0.72     (346)\n",
      "investigator    0.00      0.72     (289)\n",
      "executive       0.01      0.72     (299)\n",
      "actress         0.70      0.00     (290)\n",
      "journalist      0.02      0.68     (316)\n",
      "educator        0.03      0.67     (327)\n",
      "investor        0.01      0.66     (322)\n",
      "advisor         0.01      0.65     (279)\n",
      "administrator   0.00      0.64     (317)\n",
      "analyst         0.00      0.61     (280)\n",
      "nurse           0.60      0.36     (299)\n",
      "economist       0.01      0.56     (304)\n",
      "photographer    0.00      0.54     (302)\n",
      "engineer        0.00      0.53     (285)\n",
      "editor          0.00      0.50     (298)\n",
      "entrepreneur    0.00      0.46     (297)\n",
      "historian       0.00      0.44     (335)\n",
      "author          0.00      0.44     (306)\n",
      "agent           0.00      0.42     (298)\n",
      "artist          0.00      0.40     (295)\n",
      "escort          0.01      0.34     (289)\n",
      "intern          0.00      0.25     (282)\n",
      "organizer       0.00      0.23     (307)\n",
      "advocate        0.03      0.16     (293)\n",
      "auditor         0.00      0.14     (311)\n",
      "activist        0.01      0.05     (293)\n",
      "interpreter     0.00      0.04     (322)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "There is already a test named M/F failure rates should be similar suite. Run with overwrite=True to overwrite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-32686593f520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         print('%-13s   %.2f      %.2f     (%d)' % (prof, fail_m, fail_f, c[('man', prof)]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint_fair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'M/F failure rates should be similar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fairness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TODO: DESCRIPTION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/checklist/checklist/test_suite.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, test, name, capability, description, format_example_fn, print_fn, overwrite)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_example_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There is already a test named %s suite. Run with overwrite=True to overwrite'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: There is already a test named M/F failure rates should be similar suite. Run with overwrite=True to overwrite"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "# fewer_profs = ['doctor', 'nurse', 'secretary']\n",
    "t = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "    prof=professions + ['doctor'],\n",
    "#     prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=10000,\n",
    "    unroll=True,\n",
    "    save=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in t.data]\n",
    "labels = [d[2] for d in t.data]\n",
    "meta = [(d[3], d[4]) for d in t.data]\n",
    "\n",
    "test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates)\n",
    "test.run(new_pp)\n",
    "\n",
    "def print_fair(test):\n",
    "    c = collections.Counter(test.meta)\n",
    "    fail = collections.Counter([tuple(x) for x in np.array(test.meta)[test.fail_idxs()]])\n",
    "    profs = set()\n",
    "    for sex, prof in fail:\n",
    "        profs.add(prof)\n",
    "    prof_fail = {}\n",
    "    get_fail = lambda f:fail[f] / c[f]\n",
    "    for prof in profs:\n",
    "        fail_m = get_fail(('man', prof))\n",
    "        fail_f = get_fail(('woman', prof))\n",
    "        prof_fail[prof] = (fail_m, fail_f)\n",
    "    print('%-13s fail_men fail_women (count)' % 'profession')\n",
    "    for prof, vs in sorted(prof_fail.items(), key=lambda x:max(x[1][0], x[1][1]), reverse=True):\n",
    "        fail_m, fail_f = vs\n",
    "        print('%-13s   %.2f      %.2f     (%d)' % (prof, fail_m, fail_f, c[('man', prof)]))\n",
    "print_fair(test)\n",
    "suite.add(test, 'M/F failure rates should be similar', 'Fairness', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions.remove('actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 792 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d025eca1cd48869fb5dfc81494040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      99\n",
      "Fails (rate):    99 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Melanie and Jack are friends. He is an author, and she is a nurse.\n",
      "Q: Who is a nurse?\n",
      "A: Melanie\n",
      "P: Jack\n",
      "\n",
      "C: Jack and Melanie are friends. She is a nurse, and he is an author.\n",
      "Q: Who is an author?\n",
      "A: Jack\n",
      "P: Melanie\n",
      "\n",
      "C: Melanie and Jack are friends. She is a nurse, and he is an author.\n",
      "Q: Who is a nurse?\n",
      "A: Melanie\n",
      "P: Jack\n",
      "\n",
      "\n",
      "----\n",
      "C: Jasmine and Cody are friends. He is an agent, and she is an editor.\n",
      "Q: Who is an editor?\n",
      "A: Jasmine\n",
      "P: Cody\n",
      "\n",
      "C: Cody and Jasmine are friends. She is an editor, and he is an agent.\n",
      "Q: Who is an agent?\n",
      "A: Cody\n",
      "P: Jasmine\n",
      "\n",
      "C: Jasmine and Cody are friends. She is an editor, and he is an agent.\n",
      "Q: Who is an editor?\n",
      "A: Jasmine\n",
      "P: Cody\n",
      "\n",
      "\n",
      "----\n",
      "C: Karen and Thomas are friends. He is an accountant, and she is an academic.\n",
      "Q: Who is an academic?\n",
      "A: Karen\n",
      "P: Thomas\n",
      "\n",
      "C: Thomas and Karen are friends. She is an academic, and he is an accountant.\n",
      "Q: Who is an accountant?\n",
      "A: Thomas\n",
      "P: Karen\n",
      "\n",
      "C: Karen and Thomas are friends. She is an academic, and he is an accountant.\n",
      "Q: Who is an academic?\n",
      "A: Karen\n",
      "P: Thomas\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Basic Coref', 'Coref', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Former, latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 376 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7552d954d1234235afdb10a2032ac3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=47.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      94\n",
      "Fails (rate):    94 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Ethan and Rebecca are friends. The former is an architect.\n",
      "Q: Who is an architect?\n",
      "A: Ethan\n",
      "P: Rebecca\n",
      "\n",
      "\n",
      "----\n",
      "C: Sara and Lisa are friends. The former is an academic.\n",
      "Q: Who is an academic?\n",
      "A: Sara\n",
      "P: Lisa\n",
      "\n",
      "C: Sara and Lisa are friends. The former is an academic and the latter is an educator.\n",
      "Q: Who is an academic?\n",
      "A: Sara\n",
      "P: Lisa\n",
      "\n",
      "\n",
      "----\n",
      "C: Erin and Eric are friends. The former is an employee.\n",
      "Q: Who is an employee?\n",
      "A: Erin\n",
      "P: Eric\n",
      "\n",
      "C: Erin and Eric are friends. The former is an employee and the latter is a photographer.\n",
      "Q: Who is an employee?\n",
      "A: Erin\n",
      "P: Eric\n",
      "\n",
      "\n",
      "----\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "There is already a test named Former / Latter suite. Run with overwrite=True to overwrite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-61a9026317c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_example_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_squad_with_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Former / Latter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Coref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TODO: DESCRIPTION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/checklist/checklist/test_suite.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, test, name, capability, description, format_example_fn, print_fn, overwrite)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_example_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There is already a test named %s suite. Run with overwrite=True to overwrite'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: There is already a test named Former / Latter suite. Run with overwrite=True to overwrite"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    save=True\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Former / Latter', 'Coref', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 400 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1bc109c93348ef9dc4d135b85498a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    60 (60.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Victoria is hurt by Christian.\n",
      "Q: Who hurts?\n",
      "A: Christian\n",
      "P: Victoria\n",
      "\n",
      "\n",
      "----\n",
      "C: Jordan remembers Joseph.\n",
      "Q: Who is remembered?\n",
      "A: Joseph\n",
      "P: Jordan\n",
      "\n",
      "\n",
      "----\n",
      "C: Victoria supports Jose.\n",
      "Q: Who supports?\n",
      "A: Victoria\n",
      "P: Jose\n",
      "\n",
      "\n",
      "----\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "There is already a test named Agent / object distinction suite. Run with overwrite=True to overwrite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-20629b4d6bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_example_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_squad_with_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Agent / object distinction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SRL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TODO: DESCRIPTION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/checklist/checklist/test_suite.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, test, name, capability, description, format_example_fn, print_fn, overwrite)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_example_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There is already a test named %s suite. Run with overwrite=True to overwrite'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: There is already a test named Agent / object distinction suite. Run with overwrite=True to overwrite"
     ]
    }
   ],
   "source": [
    "import pattern\n",
    "import pattern.en\n",
    "pverb = ['love', 'hate', 'like', 'remember', 'recognize', 'trust', 'deserve', 'understand', 'blame', 'dislike', 'prefer', 'follow', 'notice', 'hurt', 'bother', 'support', 'believe', 'accept', 'attack']\n",
    "a = pattern.en.tenses('loves')[0]\n",
    "b = pattern.en.tenses('stolen')[0]\n",
    "pverb = [(pattern.en.conjugate(v, *a), pattern.en.conjugate(v, *b)) for v in pverb]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Agent / object distinction', 'SRL', 'TODO: DESCRIPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1552 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320ecb954d4745bbaa6e34818872b941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=194.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      97\n",
      "Fails (rate):    95 (97.9%)\n",
      "\n",
      "Example fails:\n",
      "C: Nicholas remembers Sophia. Sophia remembers Shannon.\n",
      "Q: Who remembers Shannon?\n",
      "A: Sophia\n",
      "P: Nicholas\n",
      "\n",
      "C: Nicholas remembers Sophia. Shannon is remembered by Sophia.\n",
      "Q: Who remembers Shannon?\n",
      "A: Sophia\n",
      "P: Nicholas\n",
      "\n",
      "C: Sophia is remembered by Nicholas. Sophia remembers Shannon.\n",
      "Q: Who is remembered by Sophia?\n",
      "A: Shannon\n",
      "P: Nicholas\n",
      "\n",
      "\n",
      "----\n",
      "C: Katherine loves Jose. Noah is loved by Jose.\n",
      "Q: Who loves Noah?\n",
      "A: Jose\n",
      "P: Katherine loves Jose. Noah is loved by Jose\n",
      "\n",
      "C: Jose is loved by Katherine. Jose loves Noah.\n",
      "Q: Who is loved by Jose?\n",
      "A: Noah\n",
      "P: Katherine\n",
      "\n",
      "C: Jose is loved by Katherine. Noah is loved by Jose.\n",
      "Q: Who is loved by Jose?\n",
      "A: Noah\n",
      "P: Katherine. Noah\n",
      "\n",
      "\n",
      "----\n",
      "C: Lisa is attacked by Jordan. Lisa attacks Samantha.\n",
      "Q: Who is attacked by Lisa?\n",
      "A: Samantha\n",
      "P: Jordan. Lisa attacks Samantha\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]} {first_name2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who {v[0]} {first_name3}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name2}?',\n",
    "                '{first_name3}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(**t, expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, 'Agent / object distinction when there are three agents', 'SRL', 'TODO: DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.save('/home/marcotcr/tmp/squad_suite.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
