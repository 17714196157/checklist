{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.mft import MFT\n",
    "from checklist.inv_dir import INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import bert_squad_model\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "model = bert_squad_model.BertSquad()\n",
    "invert = lambda a: model.predict_pairs([(x[1], x[0]) for x in a])\n",
    "new_pp = PredictorWrapper.wrap_predict(invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2253ed0e5a674f56bf9af1f6ba604ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['John']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_pairs([('Who is smarter?', 'John is smart')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<checklist.text_generation.TextGenerator at 0x7fa954d3e0f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = checklist.editor.Editor()\n",
    "editor.tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.tg.bert_tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1558218002319336"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "a = time.time()\n",
    "for _ in range(100):\n",
    "    editor.tg.unmask('This is a <mask> movie.')\n",
    "time.time() - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['C', 'atherine', 'Hep', 'burn'], 'Catherine Hepburn.', 16.481109619140625),\n",
       " (['C', 'atherine', 'Hep', 'worth'],\n",
       "  'Catherine Hepworth.',\n",
       "  15.375536918640137),\n",
       " (['D', 'ennis', 'Rod', 'man'], 'Dennis Rodman.', 15.116004943847656),\n",
       " (['C', 'atherine', 'Hep', 'ford'], 'Catherine Hepford.', 14.867422103881836),\n",
       " (['C', 'atherine', 'Hep', 'ner'], 'Catherine Hepner.', 14.864899158477783),\n",
       " (['D', 'ennis', 'Hof', 'mann'], 'Dennis Hofmann.', 14.8457932472229),\n",
       " (['D', 'ennis', 'Hof', 'stra'], 'Dennis Hofstra.', 14.72856855392456),\n",
       " (['D', 'ennis', 'Rod', 'is'], 'Dennis Rodis.', 14.48259449005127),\n",
       " (['C', 'atherine', 'Hep', 'ton'], 'Catherine Hepton.', 14.22075080871582),\n",
       " (['D', 'ennis', 'Rod', 'ricks'], 'Dennis Rodricks.', 14.125752925872803),\n",
       " (['C', 'atherine', 'Hep', 'man'], 'Catherine Hepman.', 14.094637870788574),\n",
       " (['D', 'ennis', 'Hof', 'man'], 'Dennis Hofman.', 14.080714702606201),\n",
       " (['D', 'ennis', 'Hof', 'burg'], 'Dennis Hofburg.', 14.009179592132568),\n",
       " (['D', 'ennis', 'Rod', 'in'], 'Dennis Rodin.', 13.980825424194336),\n",
       " (['C', 'atherine', 'Hep', 'born'], 'Catherine Hepborn.', 13.95168161392212),\n",
       " (['D', 'ennis', 'Rod', 'ennis'], 'Dennis Rodennis.', 13.944505214691162),\n",
       " (['C', 'atherine', 'Hep', 'han'], 'Catherine Hephan.', 13.929525375366211),\n",
       " (['C', 'atherine', 'Lang', 'ford'],\n",
       "  'Catherine Langford.',\n",
       "  13.887559652328491),\n",
       " (['D', 'ennis', 'Rod', 'ner'], 'Dennis Rodner.', 13.883644580841064),\n",
       " (['C', 'atherine', 'Hep', 'bourne'],\n",
       "  'Catherine Hepbourne.',\n",
       "  13.883506774902344),\n",
       " (['C', 'atherine', 'Hep', 'son'], 'Catherine Hepson.', 13.882439136505127),\n",
       " (['D', 'ennis', 'Hof', 'ner'], 'Dennis Hofner.', 13.870965957641602),\n",
       " (['C', 'atherine', 'Hep', 'hart'], 'Catherine Hephart.', 13.855014324188232),\n",
       " (['C', 'atherine', 'Hep', 'ener'], 'Catherine Hepener.', 13.847036838531494),\n",
       " (['D', 'ennis', 'Rod', 'ios'], 'Dennis Rodios.', 13.802987098693848),\n",
       " (['D', 'ennis', 'Rod', 'ler'], 'Dennis Rodler.', 13.782937049865723),\n",
       " (['D', 'ennis', 'Hof', 'heimer'], 'Dennis Hofheimer.', 13.738204956054688),\n",
       " (['C', 'atherine', 'Hep', 'off'], 'Catherine Hepoff.', 13.735490798950195),\n",
       " (['C', 'atherine', 'Hep', 'ning'], 'Catherine Hepning.', 13.7151780128479),\n",
       " (['C', 'atherine', 'Hep', 'field'],\n",
       "  'Catherine Hepfield.',\n",
       "  13.712347030639648),\n",
       " (['C', 'atherine', 'Hep', 'in'], 'Catherine Hepin.', 13.69349193572998),\n",
       " (['C', 'atherine', 'Hep', 'c'], 'Catherine Hepc.', 13.691242694854736),\n",
       " (['D', 'ennis', 'Hof', 'stad'], 'Dennis Hofstad.', 13.689531803131104),\n",
       " (['C', 'atherine', 'Hep', 'ett'], 'Catherine Hepett.', 13.689298629760742),\n",
       " (['D', 'ennis', 'Rod', 'ger'], 'Dennis Rodger.', 13.689158916473389),\n",
       " (['D', 'ennis', 'Rod', 'rick'], 'Dennis Rodrick.', 13.660473346710205),\n",
       " (['D', 'ennis', 'Rod', 'art'], 'Dennis Rodart.', 13.657442808151245),\n",
       " (['C', 'atherine', 'Hep', 'oun'], 'Catherine Hepoun.', 13.622725009918213),\n",
       " (['D', 'ennis', 'Rod', 'et'], 'Dennis Rodet.', 13.617275714874268),\n",
       " (['C', 'atherine', 'Hep', 'ing'], 'Catherine Heping.', 13.61454725265503),\n",
       " (['D', 'ennis', 'Rod', 'ar'], 'Dennis Rodar.', 13.559104442596436),\n",
       " (['D', 'ennis', 'Hof', 'ek'], 'Dennis Hofek.', 13.540498971939087),\n",
       " (['D', 'ennis', 'Rod', 'on'], 'Dennis Rodon.', 13.539454460144043),\n",
       " (['D', 'ennis', 'Rod', 'Smith'], 'Dennis Rod Smith.', 13.535911560058594),\n",
       " (['D', 'ennis', 'Rod', 'er'], 'Dennis Roder.', 13.51717233657837),\n",
       " (['D', 'ennis', 'Rod', 'win'], 'Dennis Rodwin.', 13.51472282409668),\n",
       " (['D', 'ennis', 'Hof', 'ende'], 'Dennis Hofende.', 13.49517297744751),\n",
       " (['D', 'ennis', 'Rod', 'ak'], 'Dennis Rodak.', 13.492579698562622),\n",
       " (['D', 'ennis', 'Rod', 'ard'], 'Dennis Rodard.', 13.491248607635498),\n",
       " (['D', 'ennis', 'Rod', 'ges'], 'Dennis Rodges.', 13.46385669708252),\n",
       " (['D', 'ennis', 'Jennings', 'Jr'], 'Dennis Jennings Jr.', 13.413612842559814),\n",
       " (['D', 'ennis', 'Hof', 'el'], 'Dennis Hofel.', 13.407413005828857),\n",
       " (['D', 'ennis', 'Hof', 'berg'], 'Dennis Hofberg.', 13.401896715164185),\n",
       " (['D', 'ennis', 'Hof', 'stadt'], 'Dennis Hofstadt.', 13.388662815093994),\n",
       " (['D', 'ennis', 'Hof', 'end'], 'Dennis Hofend.', 13.356515884399414),\n",
       " (['D', 'ennis', 'Hof', 'kamp'], 'Dennis Hofkamp.', 13.351451396942139),\n",
       " (['D', 'ennis', 'Hof', 'e'], 'Dennis Hofe.', 13.318529844284058),\n",
       " (['D', 'ennis', 'Hof', 'rock'], 'Dennis Hofrock.', 13.304849624633789),\n",
       " (['C', 'atherine', 'Lang', 'don'], 'Catherine Langdon.', 13.301604509353638),\n",
       " (['D', 'ennis', 'Hof', 'feld'], 'Dennis Hoffeld.', 13.295027732849121),\n",
       " (['D', 'ennis', 'Hof', 'land'], 'Dennis Hofland.', 13.284592628479004),\n",
       " (['D', 'ennis', 'Hof', 'son'], 'Dennis Hofson.', 13.271891355514526),\n",
       " (['D', 'ennis', 'Hof', 'meier'], 'Dennis Hofmeier.', 13.271600008010864),\n",
       " (['C', 'atherine', 'H', 'su'], 'Catherine Hsu.', 13.243887662887573),\n",
       " (['D', 'ennis', 'Anderson', 'Jr'], 'Dennis Anderson Jr.', 13.240251541137695),\n",
       " (['D', 'ennis', ',', 'John'], 'Dennis, John.', 13.208381175994873),\n",
       " (['</s>', 'Mr', '.', 'Mr'], '</s>Mr. Mr.', 13.183434247970581),\n",
       " (['</s>', 'Mr', '.', 'Smith'], '</s>Mr. Smith.', 13.174878358840942),\n",
       " (['</s>', 'Mr', '.', 'President'], '</s>Mr. President.', 13.163823366165161),\n",
       " (['C', 'atherine', 'H', 'ines'], 'Catherine Hines.', 13.093834161758423),\n",
       " (['</s>', 'Mr', '.', 'Rogers'], '</s>Mr. Rogers.', 13.048025608062744),\n",
       " (['C', 'atherine', 'Lang', 'ston'],\n",
       "  'Catherine Langston.',\n",
       "  13.037964105606079),\n",
       " (['</s>', 'Mr', '.', 'J'], '</s>Mr. J.', 13.029129266738892),\n",
       " (['C', 'atherine', 'H', 'ahn'], 'Catherine Hahn.', 13.01521110534668),\n",
       " (['C', 'atherine', 'H', 'irst'], 'Catherine Hirst.', 12.984736680984497),\n",
       " (['</s>', 'Mr', '.', 'B'], '</s>Mr. B.', 12.97965145111084),\n",
       " (['</s>', 'Mr', '.', 'T'], '</s>Mr. T.', 12.973975658416748),\n",
       " (['C', 'atherine', 'H', 'utton'], 'Catherine Hutton.', 12.966172933578491),\n",
       " (['</s>', 'Mr', '.', 'Watson'], '</s>Mr. Watson.', 12.959561586380005),\n",
       " (['C', 'atherine', 'H', 'ickey'], 'Catherine Hickey.', 12.947021961212158),\n",
       " (['C', 'atherine', 'Lang', 'ley'], 'Catherine Langley.', 12.923887014389038),\n",
       " (['</s>', 'Mr', '.', 'Brown'], '</s>Mr. Brown.', 12.921569347381592),\n",
       " (['</s>', 'Mr', '.', 'A'], '</s>Mr. A.', 12.912694692611694),\n",
       " (['D', 'ennis', 'Jennings', 'Sr'], 'Dennis Jennings Sr.', 12.911272048950195),\n",
       " (['</s>', 'Mr', '.', 'F'], '</s>Mr. F.', 12.909191370010376),\n",
       " (['C', 'atherine', 'H', 'ynes'], 'Catherine Hynes.', 12.89290165901184),\n",
       " (['C', 'atherine', 'H', 'oyle'], 'Catherine Hoyle.', 12.878396272659302),\n",
       " (['D', 'ennis', ',', 'Dennis'], 'Dennis, Dennis.', 12.87820291519165),\n",
       " (['</s>', 'Mr', '.', 'H'], '</s>Mr. H.', 12.873178482055664),\n",
       " (['</s>', 'Mr', '.', 'G'], '</s>Mr. G.', 12.86664366722107),\n",
       " (['D', 'ennis', 'Jennings', 'III'],\n",
       "  'Dennis Jennings III.',\n",
       "  12.863551139831543),\n",
       " (['C', 'atherine', 'H', 'enson'], 'Catherine Henson.', 12.835591793060303),\n",
       " (['C', 'atherine', 'H', 'odge'], 'Catherine Hodge.', 12.831278562545776),\n",
       " (['</s>', 'Mr', '.', 'Johnson'], '</s>Mr. Johnson.', 12.827441453933716),\n",
       " (['</s>', 'Mr', '.', 'D'], '</s>Mr. D.', 12.826570272445679),\n",
       " (['C', 'atherine', 'H', 'wang'], 'Catherine Hwang.', 12.81995964050293),\n",
       " (['</s>', 'Mr', '.', 'King'], '</s>Mr. King.', 12.818605661392212),\n",
       " (['</s>', 'Mr', '.', 'C'], '</s>Mr. C.', 12.818543195724487),\n",
       " (['</s>', 'Mr', '.', 'Speaker'], '</s>Mr. Speaker.', 12.80882716178894),\n",
       " (['</s>', 'Mr', '.', 'Mayor'], '</s>Mr. Mayor.', 12.801769733428955),\n",
       " (['</s>', 'Mr', '.', 'K'], '</s>Mr. K.', 12.799460172653198),\n",
       " (['C', 'atherine', 'H', 'anks'], 'Catherine Hanks.', 12.762126207351685),\n",
       " (['C', 'atherine', 'Lang', 'an'], 'Catherine Langan.', 12.723165273666382),\n",
       " (['C', 'atherine', 'H', 'agan'], 'Catherine Hagan.', 12.722782373428345),\n",
       " (['C', 'atherine', 'H', 'oman'], 'Catherine Homan.', 12.72163701057434),\n",
       " (['C', 'atherine', 'H', 'urd'], 'Catherine Hurd.', 12.701788902282715),\n",
       " (['C', 'atherine', 'H', 'ester'], 'Catherine Hester.', 12.700360536575317),\n",
       " (['D', 'ennis', ',', 'Robert'], 'Dennis, Robert.', 12.683953762054443),\n",
       " (['C', 'atherine', 'H', 'ushing'], 'Catherine Hushing.', 12.662195920944214),\n",
       " (['D', 'ennis', 'Anderson', 'III'],\n",
       "  'Dennis Anderson III.',\n",
       "  12.65261459350586),\n",
       " (['D', 'ennis', 'Anderson', 'vs'], 'Dennis Anderson vs.', 12.652612209320068),\n",
       " (['C', 'atherine', 'H', 'esse'], 'Catherine Hesse.', 12.635279417037964),\n",
       " (['D', 'ennis', ',', 'Charles'], 'Dennis, Charles.', 12.633248329162598),\n",
       " (['C', 'atherine', 'H', 'ames'], 'Catherine Hames.', 12.62250566482544),\n",
       " (['D', 'ennis', 'Jennings', 'IV'], 'Dennis Jennings IV.', 12.614710330963135),\n",
       " (['C', 'atherine', 'H', 'ix'], 'Catherine Hix.', 12.609699010848999),\n",
       " (['D', 'ennis', ',', 'Raymond'], 'Dennis, Raymond.', 12.604183912277222),\n",
       " (['D', 'ennis', ',', 'Jr'], 'Dennis, Jr.', 12.572272777557373),\n",
       " (['C', 'atherine', 'Lang', 'dale'],\n",
       "  'Catherine Langdale.',\n",
       "  12.561346292495728),\n",
       " (['D', 'ennis', 'Anderson', 'Sr'], 'Dennis Anderson Sr.', 12.557411193847656),\n",
       " (['C', 'atherine', 'Lang', 'man'], 'Catherine Langman.', 12.533721685409546),\n",
       " (['D', 'ennis', ',', 'Thomas'], 'Dennis, Thomas.', 12.524391651153564),\n",
       " (['C', 'atherine', 'Lang', 'more'],\n",
       "  'Catherine Langmore.',\n",
       "  12.503103017807007),\n",
       " (['C', 'atherine', 'Lang', 'Lang'],\n",
       "  'Catherine Lang Lang.',\n",
       "  12.475244522094727),\n",
       " (['D', 'ennis', 'Jennings', 'retired'],\n",
       "  'Dennis Jennings retired.',\n",
       "  12.445296049118042),\n",
       " (['D', 'ennis', 'Jennings', 'vs'], 'Dennis Jennings vs.', 12.408518552780151),\n",
       " (['C', 'atherine', 'Lang', 'ner'], 'Catherine Langner.', 12.401356935501099),\n",
       " (['C', 'atherine', 'Lang', 'try'], 'Catherine Langtry.', 12.40132761001587),\n",
       " (['D', 'ennis', ',', 'Bob'], 'Dennis, Bob.', 12.400194644927979),\n",
       " (['C', 'atherine', 'Lang', 'wood'],\n",
       "  'Catherine Langwood.',\n",
       "  12.389111757278442),\n",
       " (['C', 'atherine', 'Lang', 'ton'], 'Catherine Langton.', 12.374901533126831),\n",
       " (['D', 'ennis', ',', 'Donald'], 'Dennis, Donald.', 12.351171970367432),\n",
       " (['D', 'ennis', ',', 'Rod'], 'Dennis, Rod.', 12.3185715675354),\n",
       " (['D', 'ennis', 'Anderson', 'disagrees'],\n",
       "  'Dennis Anderson disagrees.',\n",
       "  12.304456233978271),\n",
       " (['D', 'ennis', ',', 'Tony'], 'Dennis, Tony.', 12.299924373626709),\n",
       " (['D', 'ennis', 'Anderson', 'IV'], 'Dennis Anderson IV.', 12.291217803955078),\n",
       " (['C', 'atherine', 'Lang', 'ame'], 'Catherine Langame.', 12.266995429992676),\n",
       " (['D', 'ennis', ',', 'Jim'], 'Dennis, Jim.', 12.264008283615112),\n",
       " (['C', 'atherine', 'Lang', 'land'], 'Catherine Langland.', 12.26314115524292),\n",
       " (['D', 'ennis', ',', 'Phil'], 'Dennis, Phil.', 12.260250806808472),\n",
       " (['D', 'ennis', ',', 'Andy'], 'Dennis, Andy.', 12.25940465927124),\n",
       " (['D', 'ennis', ',', 'Jon'], 'Dennis, Jon.', 12.25899076461792),\n",
       " (['D', 'ennis', 'Anderson', 'retired'],\n",
       "  'Dennis Anderson retired.',\n",
       "  12.253888607025146),\n",
       " (['C', 'atherine', 'Lang', 'field'],\n",
       "  'Catherine Langfield.',\n",
       "  12.250882863998413),\n",
       " (['C', 'atherine', 'Lang', 'strom'],\n",
       "  'Catherine Langstrom.',\n",
       "  12.249083042144775),\n",
       " (['D', 'ennis', ',', 'Keith'], 'Dennis, Keith.', 12.248382568359375),\n",
       " (['D', 'ennis', ',', 'too'], 'Dennis, too.', 12.23855209350586),\n",
       " (['D', 'ennis', 'Jennings', 'II'], 'Dennis Jennings II.', 12.235066890716553),\n",
       " (['C', 'atherine', 'Lang', 'ridge'],\n",
       "  'Catherine Langridge.',\n",
       "  12.227185726165771),\n",
       " (['C', 'atherine', 'Lang', 'oon'], 'Catherine Langoon.', 12.226949691772461),\n",
       " (['D', 'ennis', 'Anderson', '</s>'],\n",
       "  'Dennis Anderson</s>.',\n",
       "  12.215383291244507),\n",
       " (['D', 'ennis', ',', 'Michael'], 'Dennis, Michael.', 12.204915523529053),\n",
       " (['D', 'ennis', ',', 'R'], 'Dennis, R.', 12.203433990478516),\n",
       " (['C', 'atherine', 'Lang', 'den'], 'Catherine Langden.', 12.199191331863403),\n",
       " (['D', 'ennis', ',', 'Edmund'], 'Dennis, Edmund.', 12.188049793243408),\n",
       " (['D', 'ennis', 'Jennings', 'died'],\n",
       "  'Dennis Jennings died.',\n",
       "  12.18266248703003),\n",
       " (['D', 'ennis', 'Anderson', 'dies'],\n",
       "  'Dennis Anderson dies.',\n",
       "  12.109280824661255),\n",
       " (['D', 'ennis', 'Jennings', 'dies'],\n",
       "  'Dennis Jennings dies.',\n",
       "  12.074440956115723),\n",
       " (['</s>', 'I', \"'m\", 'sorry'], \"</s>I'm sorry.\", 12.070207357406616),\n",
       " (['D', 'ennis', 'Jennings', '</s>'],\n",
       "  'Dennis Jennings</s>.',\n",
       "  12.041170120239258),\n",
       " (['D', 'ennis', 'Jennings', 'JR'], 'Dennis Jennings JR.', 12.037219047546387),\n",
       " (['D', 'ennis', 'Anderson', 'wins'],\n",
       "  'Dennis Anderson wins.',\n",
       "  12.02068305015564),\n",
       " (['D', 'ennis', 'Anderson', 'No'], 'Dennis Anderson No.', 12.009647846221924),\n",
       " (['D', 'ennis', 'Anderson', 'died'],\n",
       "  'Dennis Anderson died.',\n",
       "  12.002704620361328),\n",
       " (['</s>', 'I', \"'m\", 'Kevin'], \"</s>I'm Kevin.\", 11.9925057888031),\n",
       " (['D', 'ennis', 'Jennings', '2'], 'Dennis Jennings 2.', 11.990124702453613),\n",
       " (['D', 'ennis', 'Anderson', 'II'], 'Dennis Anderson II.', 11.985429286956787),\n",
       " (['</s>', 'I', \"'m\", 'back'], \"</s>I'm back.\", 11.984507322311401),\n",
       " (['</s>', 'I', \"'m\", 'David'], \"</s>I'm David.\", 11.982151985168457),\n",
       " (['D', 'ennis', 'Jennings', 'won'],\n",
       "  'Dennis Jennings won.',\n",
       "  11.938682079315186),\n",
       " (['</s>', 'I', \"'m\", 'John'], \"</s>I'm John.\", 11.932045698165894),\n",
       " (['</s>', 'I', \"'m\", 'Chris'], \"</s>I'm Chris.\", 11.92203426361084),\n",
       " (['D', 'ennis', 'Jennings', '3'], 'Dennis Jennings 3.', 11.913367748260498),\n",
       " (['</s>', 'I', \"'m\", 'Bill'], \"</s>I'm Bill.\", 11.910458326339722),\n",
       " (['D', 'ennis', 'Anderson', 'speaks'],\n",
       "  'Dennis Anderson speaks.',\n",
       "  11.909265995025635),\n",
       " (['D', 'ennis', 'Jennings', '83'], 'Dennis Jennings 83.', 11.906938076019287),\n",
       " (['D', 'ennis', 'Anderson', 'won'],\n",
       "  'Dennis Anderson won.',\n",
       "  11.90208911895752),\n",
       " (['</s>', 'I', \"'m\", 'Mark'], \"</s>I'm Mark.\", 11.898828744888306),\n",
       " (['</s>', 'I', \"'m\", 'Steve'], \"</s>I'm Steve.\", 11.897993326187134),\n",
       " (['D', 'ennis', 'Anderson', 'JR'], 'Dennis Anderson JR.', 11.897721290588379),\n",
       " (['D', 'ennis', 'Anderson', 'said'],\n",
       "  'Dennis Anderson said.',\n",
       "  11.886809587478638),\n",
       " (['D', 'ennis', 'Anderson', '1973'],\n",
       "  'Dennis Anderson 1973.',\n",
       "  11.876003980636597),\n",
       " (['D', 'ennis', 'Jennings', 'No'], 'Dennis Jennings No.', 11.873869895935059),\n",
       " (['D', 'ennis', 'Anderson', 'agrees'],\n",
       "  'Dennis Anderson agrees.',\n",
       "  11.863808870315552),\n",
       " (['D', 'ennis', 'Anderson', '2'], 'Dennis Anderson 2.', 11.853752851486206),\n",
       " (['</s>', 'I', \"'m\", 'Mike'], \"</s>I'm Mike.\", 11.853586435317993),\n",
       " (['</s>', 'I', \"'m\", 'Dave'], \"</s>I'm Dave.\", 11.85083556175232),\n",
       " (['</s>', 'I', \"'m\", 'Ben'], \"</s>I'm Ben.\", 11.837509393692017),\n",
       " (['</s>', 'I', \"'m\", 'Matt'], \"</s>I'm Matt.\", 11.835730791091919),\n",
       " (['</s>', 'I', \"'m\", 'Henry'], \"</s>I'm Henry.\", 11.831527709960938),\n",
       " (['</s>', 'I', \"'m\", 'Andrew'], \"</s>I'm Andrew.\", 11.83085298538208),\n",
       " (['</s>', 'I', \"'m\", 'Brian'], \"</s>I'm Brian.\", 11.829362154006958),\n",
       " (['</s>', 'I', \"'m\", 'Joe'], \"</s>I'm Joe.\", 11.81108570098877),\n",
       " (['</s>', 'I', \"'m\", 'Brad'], \"</s>I'm Brad.\", 11.80656361579895),\n",
       " (['</s>', 'I', \"'m\", 'Scott'], \"</s>I'm Scott.\", 11.804580450057983),\n",
       " (['D', 'ennis', 'Jennings', '78'], 'Dennis Jennings 78.', 11.80436396598816),\n",
       " (['</s>', 'I', \"'m\", 'Christian'], \"</s>I'm Christian.\", 11.800301790237427),\n",
       " (['D', 'ennis', 'Jennings', 'said'],\n",
       "  'Dennis Jennings said.',\n",
       "  11.79201865196228),\n",
       " (['D', 'ennis', 'Jennings', 'disagrees'],\n",
       "  'Dennis Jennings disagrees.',\n",
       "  11.775135517120361),\n",
       " (['D', 'ennis', 'Jennings', '88'], 'Dennis Jennings 88.', 11.774499416351318)]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.tg.unmask('<mask> <mask> <mask> <mask>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([\"'s\", 'long', 'story'], \" John's a long story.\", 13.168134053548178),\n",
       " (['have', 'great', 'weekend'],\n",
       "  ' John have a great weekend.',\n",
       "  13.093008359273275),\n",
       " (['have', 'great', 'day'], ' John have a great day.', 13.035822232564291),\n",
       " ([\"'s\", 'long', 'shot'], \" John's a long shot.\", 12.757226626078287),\n",
       " ([\"'s\", 'good', 'question'], \" John's a good question.\", 12.732789357503256),\n",
       " ([\"'s\", 'long', 'time'], \" John's a long time.\", 12.64133389790853),\n",
       " (['have', 'great', 'week'], ' John have a great week.', 12.60458787282308),\n",
       " ([\"'s\", 'good', 'start'], \" John's a good start.\", 12.509771664937338),\n",
       " (['have', 'great', 'time'], ' John have a great time.', 12.489199956258139),\n",
       " ([\"'s\", 'big', 'deal'], \" John's a big deal.\", 12.464763959248861),\n",
       " (['have', 'great', 'evening'],\n",
       "  ' John have a great evening.',\n",
       "  12.417716026306152),\n",
       " ([\"'s\", 'long', 'list'], \" John's a long list.\", 12.405047098795572),\n",
       " ([\"'s\", 'good', 'one'], \" John's a good one.\", 12.36998208363851),\n",
       " (['have', 'great', 'night'], ' John have a great night.', 12.368513425191244),\n",
       " ([\"'s\", 'good', 'idea'], \" John's a good idea.\", 12.280694325764975),\n",
       " ([\"'s\", 'great', 'question'],\n",
       "  \" John's a great question.\",\n",
       "  12.277661323547363),\n",
       " ([\"'s\", 'long', 'day'], \" John's a long day.\", 12.253352483113607),\n",
       " ([\"'s\", 'good', 'sign'], \" John's a good sign.\", 12.252847035725912),\n",
       " ([\"'s\", 'good', 'point'], \" John's a good point.\", 12.229620615641275),\n",
       " ([\"'s\", 'long', 'one'], \" John's a long one.\", 12.175647099812826),\n",
       " ([\"'s\", 'good', 'example'], \" John's a good example.\", 12.152360916137695),\n",
       " (['have', 'great', 'year'], ' John have a great year.', 12.134696006774902),\n",
       " ([\"'s\", 'nice', 'guy'], \" John's a nice guy.\", 12.104647000630697),\n",
       " ([\"'s\", 'long', 'read'], \" John's a long read.\", 12.068250020345053),\n",
       " ([\"'s\", 'great', 'story'], \" John's a great story.\", 12.037894566853842),\n",
       " ([\"'s\", 'great', 'idea'], \" John's a great idea.\", 12.032822291056315),\n",
       " ([\"'s\", 'good', 'story'], \" John's a good story.\", 11.992273330688477),\n",
       " ([\"'s\", 'good', 'thing'], \" John's a good thing.\", 11.964734395345053),\n",
       " (['have', 'great', 'summer'],\n",
       "  ' John have a great summer.',\n",
       "  11.958938598632812),\n",
       " ([\"'s\", 'good', 'read'], \" John's a good read.\", 11.947292963663736),\n",
       " ([\"'s\", 'great', 'read'], \" John's a great read.\", 11.946778297424316),\n",
       " (['have', 'great', 'holiday'],\n",
       "  ' John have a great holiday.',\n",
       "  11.933794975280762),\n",
       " ([\"'s\", 'long', 'essay'], \" John's a long essay.\", 11.922402064005533),\n",
       " ([\"'s\", 'big', 'difference'],\n",
       "  \" John's a big difference.\",\n",
       "  11.911545435587565),\n",
       " (['have', 'great', 'Thanksgiving'],\n",
       "  ' John have a great Thanksgiving.',\n",
       "  11.904692014058432),\n",
       " ([\"'s\", 'good', 'guy'], \" John's a good guy.\", 11.898690223693848),\n",
       " ([\"'s\", 'good', 'day'], \" John's a good day.\", 11.888302167256674),\n",
       " ([\"'s\", 'great', 'article'], \" John's a great article.\", 11.878440856933594),\n",
       " ([\"'s\", 'long', 'post'], \" John's a long post.\", 11.876153628031412),\n",
       " ([\"'s\", 'good', 'time'], \" John's a good time.\", 11.871365229288736),\n",
       " (['is', 'new', 'post'], ' John is a new post.', 11.854475975036621),\n",
       " (['is', 'good', 'question'], ' John is a good question.', 11.851024627685547),\n",
       " ([\"'s\", 'great', 'guy'], \" John's a great guy.\", 11.8463347752889),\n",
       " ([\"'s\", 'good', 'shot'], \" John's a good shot.\", 11.838689804077148),\n",
       " ([\"'s\", 'good', 'look'], \" John's a good look.\", 11.808412869771322),\n",
       " ([\"'s\", 'good', 'argument'], \" John's a good argument.\", 11.802850723266602),\n",
       " (['have', 'great', 'afternoon'],\n",
       "  ' John have a great afternoon.',\n",
       "  11.79419740041097),\n",
       " ([\"'s\", 'good', 'analogy'], \" John's a good analogy.\", 11.7855224609375),\n",
       " ([\"'s\", 'long', 'way'], \" John's a long way.\", 11.773657162984213),\n",
       " (['is', 'good', 'start'], ' John is a good start.', 11.757224400838217),\n",
       " ([\"'s\", 'good', 'call'], \" John's a good call.\", 11.752196629842123),\n",
       " (['have', 'great', 'morning'],\n",
       "  ' John have a great morning.',\n",
       "  11.741209348042807),\n",
       " ([\"'s\", 'little', 'more'], \" John's a little more.\", 11.740514755249023),\n",
       " ([\"'s\", 'nice', 'story'], \" John's a nice story.\", 11.734067916870117),\n",
       " (['have', 'great', 'trip'], ' John have a great trip.', 11.716935157775879),\n",
       " ([\"'s\", 'great', 'song'], \" John's a great song.\", 11.71028995513916),\n",
       " ([\"'s\", 'long', 'haul'], \" John's a long haul.\", 11.695642471313477),\n",
       " (['have', 'great', 'Christmas'],\n",
       "  ' John have a great Christmas.',\n",
       "  11.681214014689127),\n",
       " (['is', 'good', 'example'], ' John is a good example.', 11.671171188354492),\n",
       " ([\"'s\", 'great', 'example'], \" John's a great example.\", 11.669717788696289),\n",
       " ([\"'s\", 'great', 'start'], \" John's a great start.\", 11.669382413228353),\n",
       " ([\"'s\", 'great', 'point'], \" John's a great point.\", 11.668088912963867),\n",
       " ([\"'s\", 'good', 'line'], \" John's a good line.\", 11.667987823486328),\n",
       " ([\"'s\", 'good', 'job'], \" John's a good job.\", 11.665537516276041),\n",
       " ([\"'s\", 'great', 'quote'], \" John's a great quote.\", 11.65645440419515),\n",
       " (['is', 'good', 'idea'], ' John is a good idea.', 11.656367619832357),\n",
       " ([\"'s\", 'long', 'process'], \" John's a long process.\", 11.651436487833658),\n",
       " (['have', 'great', 'month'], ' John have a great month.', 11.649698575337728),\n",
       " (['is', 'great', 'read'], ' John is a great read.', 11.646787961324057),\n",
       " ([\"'s\", 'great', 'analogy'], \" John's a great analogy.\", 11.637137730916342),\n",
       " ([\"'s\", 'great', 'post'], \" John's a great post.\", 11.627479871114096),\n",
       " ([\"'s\", 'nice', 'idea'], \" John's a nice idea.\", 11.625638961791992),\n",
       " ([\"'s\", 'long', 'weekend'], \" John's a long weekend.\", 11.622857093811035),\n",
       " ([\"'s\", 'long', 'year'], \" John's a long year.\", 11.618947982788086),\n",
       " (['is', 'great', 'article'], ' John is a great article.', 11.606186548868815),\n",
       " ([\"'s\", 'long', 'article'], \" John's a long article.\", 11.604400952657064),\n",
       " ([\"'s\", 'big', 'one'], \" John's a big one.\", 11.604085922241211),\n",
       " ([\"'s\", 'long', 'walk'], \" John's a long walk.\", 11.600155194600424),\n",
       " ([\"'s\", 'long', 'journey'], \" John's a long journey.\", 11.599966684977213),\n",
       " ([\"'s\", 'great', 'pick'], \" John's a great pick.\", 11.59878921508789),\n",
       " (['is', 'great', 'story'], ' John is a great story.', 11.592663129170736),\n",
       " ([\"'s\", 'long', 'wait'], \" John's a long wait.\", 11.581385930379232),\n",
       " ([\"'s\", 'great', 'interview'],\n",
       "  \" John's a great interview.\",\n",
       "  11.572456359863281),\n",
       " ([\"'s\", 'nice', 'touch'], \" John's a nice touch.\", 11.568942387898764),\n",
       " ([\"'s\", 'long', 'season'], \" John's a long season.\", 11.565319061279297),\n",
       " (['is', 'great', 'guy'], ' John is a great guy.', 11.561331431070963),\n",
       " (['have', 'great', 'game'], ' John have a great game.', 11.55854574839274),\n",
       " ([\"'s\", 'long', 'take'], \" John's a long take.\", 11.557917912801107),\n",
       " (['is', 'new', 'article'], ' John is a new article.', 11.556409200032553),\n",
       " ([\"'s\", 'big', 'thing'], \" John's a big thing.\", 11.551753997802734),\n",
       " ([\"'s\", 'nice', 'thought'], \" John's a nice thought.\", 11.538787206013998),\n",
       " ([\"'s\", 'great', 'list'], \" John's a great list.\", 11.534875551859537),\n",
       " ([\"'s\", 'great', 'book'], \" John's a great book.\", 11.531769434611002),\n",
       " (['have', 'great', 'Saturday'],\n",
       "  ' John have a great Saturday.',\n",
       "  11.525418599446615),\n",
       " ([\"'s\", 'great', 'movie'], \" John's a great movie.\", 11.520004908243815),\n",
       " ([\"'s\", 'great', 'line'], \" John's a great line.\", 11.515033086140951),\n",
       " (['is', 'great', 'question'],\n",
       "  ' John is a great question.',\n",
       "  11.498806317647299),\n",
       " (['is', 'good', 'point'], ' John is a good point.', 11.494161605834961),\n",
       " (['have', 'great', 'one'], ' John have a great one.', 11.493069648742676),\n",
       " (['is', 'new', 'video'], ' John is a new video.', 11.488622665405273),\n",
       " (['is', 'good', 'one'], ' John is a good one.', 11.487128257751465),\n",
       " (['have', 'great', 'Halloween'],\n",
       "  ' John have a great Halloween.',\n",
       "  11.479124387105307),\n",
       " (['is', 'good', 'sign'], ' John is a good sign.', 11.478093465169271),\n",
       " ([\"'s\", 'great', 'time'], \" John's a great time.\", 11.4744021097819),\n",
       " ([\"'s\", 'big', 'mistake'], \" John's a big mistake.\", 11.46839173634847),\n",
       " (['is', 'great', 'idea'], ' John is a great idea.', 11.45993455251058),\n",
       " ([\"'s\", 'little', 'different'],\n",
       "  \" John's a little different.\",\n",
       "  11.458636601765951),\n",
       " ([\"'s\", 'nice', 'man'], \" John's a nice man.\", 11.438021977742514),\n",
       " ([\"'s\", 'big', 'problem'], \" John's a big problem.\", 11.437733014424643),\n",
       " ([\"'s\", 'little', 'longer'], \" John's a little longer.\", 11.420572916666666),\n",
       " (['have', 'great', 'life'], ' John have a great life.', 11.419208208719889),\n",
       " (['is', 'great', 'example'], ' John is a great example.', 11.410229682922363),\n",
       " ([\"'s\", 'little', 'scary'], \" John's a little scary.\", 11.380026499430338),\n",
       " (['is', 'new', 'version'], ' John is a new version.', 11.373963038126627),\n",
       " ([\"'s\", 'nice', 'read'], \" John's a nice read.\", 11.363430658976236),\n",
       " (['is', 'good', 'read'], ' John is a good read.', 11.36170228322347),\n",
       " (['is', 'new', 'story'], ' John is a new story.', 11.34140650431315),\n",
       " ([\"'s\", 'little', 'closer'], \" John's a little closer.\", 11.33878262837728),\n",
       " (['is', 'good', 'guy'], ' John is a good guy.', 11.33060073852539),\n",
       " (['is', 'new', 'episode'], ' John is a new episode.', 11.328283627827963),\n",
       " (['is', 'good', 'story'], ' John is a good story.', 11.324029286702475),\n",
       " (['is', 'new', 'year'], ' John is a new year.', 11.322381019592285),\n",
       " (['is', 'great', 'book'], ' John is a great book.', 11.315448443094889),\n",
       " ([\"'s\", 'big', 'change'], \" John's a big change.\", 11.293317476908365),\n",
       " ([\"'s\", 'nice', 'day'], \" John's a nice day.\", 11.291838010152182),\n",
       " (['is', 'new', 'page'], ' John is a new page.', 11.28837521870931),\n",
       " (['is', 'good', 'time'], ' John is a good time.', 11.281198183695475),\n",
       " ([\"'s\", 'nice', 'song'], \" John's a nice song.\", 11.2782351175944),\n",
       " (['is', 'good', 'thing'], ' John is a good thing.', 11.2727902730306),\n",
       " (['is', 'new', 'chapter'], ' John is a new chapter.', 11.267093022664389),\n",
       " ([\"'s\", 'nice', 'view'], \" John's a nice view.\", 11.265258153279623),\n",
       " ([\"'s\", 'little', 'fun'], \" John's a little fun.\", 11.262054443359375),\n",
       " ([\"'s\", 'nice', 'thing'], \" John's a nice thing.\", 11.232285499572754),\n",
       " (['is', 'good', 'book'], ' John is a good book.', 11.231343269348145),\n",
       " (['is', 'new', 'feature'], ' John is a new feature.', 11.227848052978516),\n",
       " (['is', 'new', 'series'], ' John is a new series.', 11.213818868001303),\n",
       " (['is', 'great', 'writer'], ' John is a great writer.', 11.210480372111002),\n",
       " ([\"'s\", 'little', 'bit'], \" John's a little bit.\", 11.208203633626303),\n",
       " ([\"'s\", 'little', 'graphic'],\n",
       "  \" John's a little graphic.\",\n",
       "  11.207069714864096),\n",
       " ([\"'s\", 'nice', 'feeling'], \" John's a nice feeling.\", 11.203008651733398),\n",
       " ([\"'s\", 'little', 'better'], \" John's a little better.\", 11.202651341756185),\n",
       " (['is', 'new', 'day'], ' John is a new day.', 11.19952360788981),\n",
       " (['is', 'great', 'post'], ' John is a great post.', 11.196783065795898),\n",
       " ([\"'s\", 'big', 'step'], \" John's a big step.\", 11.195199648539225),\n",
       " (['is', 'great', 'quote'], ' John is a great quote.', 11.179704984029135),\n",
       " (['is', 'good', 'day'], ' John is a good day.', 11.178630828857422),\n",
       " (['is', 'great', 'pick'], ' John is a great pick.', 11.17817242940267),\n",
       " (['is', 'new', 'site'], ' John is a new site.', 11.171821594238281),\n",
       " (['is', 'new', 'entry'], ' John is a new entry.', 11.169612884521484),\n",
       " (['is', 'good', 'argument'], ' John is a good argument.', 11.164827664693197),\n",
       " (['is', 'great', 'interview'],\n",
       "  ' John is a great interview.',\n",
       "  11.156033515930176),\n",
       " ([\"'s\", 'little', 'tricky'], \" John's a little tricky.\", 11.1494509379069),\n",
       " ([\"'s\", 'little', 'deeper'], \" John's a little deeper.\", 11.144228299458822),\n",
       " ([\"'s\", 'nice', 'picture'], \" John's a nice picture.\", 11.142106056213379),\n",
       " (['is', 'great', 'list'], ' John is a great list.', 11.140146891276041),\n",
       " ([\"'s\", 'little', 'easier'], \" John's a little easier.\", 11.130779266357422),\n",
       " ([\"'s\", 'nice', 'question'], \" John's a nice question.\", 11.123061180114746),\n",
       " ([\"'s\", 'nice', 'movie'], \" John's a nice movie.\", 11.118712743123373),\n",
       " ([\"'s\", 'nice', 'article'], \" John's a nice article.\", 11.112764676411947),\n",
       " ([\"'s\", 'big', 'question'], \" John's a big question.\", 11.111950238545736),\n",
       " ([\"'s\", 'nice', 'point'], \" John's a nice point.\", 11.110719045003256),\n",
       " (['is', 'great', 'song'], ' John is a great song.', 11.10057004292806),\n",
       " ([\"'s\", 'nice', 'sign'], \" John's a nice sign.\", 11.096519788106283),\n",
       " ([\"'s\", 'nice', 'person'], \" John's a nice person.\", 11.093901952107748),\n",
       " (['is', 'good', 'analogy'], ' John is a good analogy.', 11.093056996663412),\n",
       " ([\"'s\", 'nice', 'start'], \" John's a nice start.\", 11.091818491617838),\n",
       " ([\"'s\", 'big', 'win'], \" John's a big win.\", 11.08387279510498),\n",
       " ([\"'s\", 'little', 'video'], \" John's a little video.\", 11.076463063557943),\n",
       " ([\"'s\", 'little', 'quiz'], \" John's a little quiz.\", 11.076443354288736),\n",
       " (['is', 'good', 'list'], ' John is a good list.', 11.074103037516275),\n",
       " ([\"'s\", 'big', 'picture'], \" John's a big picture.\", 11.07373841603597),\n",
       " (['is', 'great', 'time'], ' John is a great time.', 11.054791450500488),\n",
       " (['is', 'great', 'start'], ' John is a great start.', 11.05090045928955),\n",
       " ([\"'s\", 'little', 'further'],\n",
       "  \" John's a little further.\",\n",
       "  11.042338371276855),\n",
       " ([\"'s\", 'little', 'sad'], \" John's a little sad.\", 11.03729248046875),\n",
       " (['is', 'great', 'man'], ' John is a great man.', 11.035241762797037),\n",
       " (['is', 'good', 'pick'], ' John is a good pick.', 11.029508590698242),\n",
       " (['is', 'great', 'point'], ' John is a great point.', 11.025370915730795),\n",
       " ([\"'s\", 'big', 'leap'], \" John's a big leap.\", 11.02019182840983),\n",
       " ([\"'s\", 'little', 'harder'], \" John's a little harder.\", 11.01752789815267),\n",
       " (['is', 'great', 'game'], ' John is a great game.', 11.014653205871582),\n",
       " ([\"'s\", 'little', 'story'], \" John's a little story.\", 11.013999938964844),\n",
       " ([\"'s\", 'little', 'embarrassing'],\n",
       "  \" John's a little embarrassing.\",\n",
       "  11.012557983398438),\n",
       " (['is', 'good', 'job'], ' John is a good job.', 11.010241508483887),\n",
       " ([\"'s\", 'little', 'history'],\n",
       "  \" John's a little history.\",\n",
       "  11.006038665771484),\n",
       " ([\"'s\", 'big', 'guy'], \" John's a big guy.\", 11.002668380737305),\n",
       " (['is', 'good', 'answer'], ' John is a good answer.', 10.995346387227377),\n",
       " ([\"'s\", 'big', 'world'], \" John's a big world.\", 10.983752886454264),\n",
       " ([\"'s\", 'big', 'city'], \" John's a big city.\", 10.980450630187988),\n",
       " (['is', 'new', 'website'], ' John is a new website.', 10.959684054056803),\n",
       " ([\"'s\", 'big', 'loss'], \" John's a big loss.\", 10.94351609547933),\n",
       " ([\"'s\", 'big', 'job'], \" John's a big job.\", 10.941793123881022),\n",
       " (['is', 'new', 'one'], ' John is a new one.', 10.935370445251465),\n",
       " ([\"'s\", 'big', 'boy'], \" John's a big boy.\", 10.932632128397623),\n",
       " (['is', 'new', 'game'], ' John is a new game.', 10.922337849934896),\n",
       " (['is', 'new', 'blog'], ' John is a new blog.', 10.90666389465332),\n",
       " (['is', 'new', 'bie'], ' John is a newbie.', 10.894769032796225),\n",
       " ([\"'s\", 'big', 'surprise'], \" John's a big surprise.\", 10.894465446472168),\n",
       " ([\"'s\", 'big', 'day'], \" John's a big day.\", 10.889169692993164),\n",
       " (['is', 'new', 'addition'], ' John is a new addition.', 10.86531925201416)]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.tg.unmask('John <mask> a <mask> <mask>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad_with_context(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'C: %s\\nQ: %s\\n' % (c, q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'Q: %s\\n' % (q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_squad(fold='validation'):\n",
    "    answers = []\n",
    "    data = []\n",
    "    ids = []\n",
    "    files = {\n",
    "        'validation': '/home/marcotcr/datasets/squad/dev-v1.1.json',\n",
    "        'train': '/home/marcotcr//datasets/squad/train-v1.1.json',\n",
    "        }\n",
    "    f = json.load(open(files[fold]))\n",
    "    for t in f['data']:\n",
    "        for p in t['paragraphs']:\n",
    "            context = p['context']\n",
    "            for qa in p['qas']:\n",
    "                data.append({'passage': context, 'question': qa['question'], 'id': qa['id']})\n",
    "                answers.append(set([(x['text'], x['answer_start']) for x in qa['answers']]))\n",
    "    return data, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data, answers =  load_squad()\n",
    "spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_squad.pkl', 'rb'))\n",
    "pairs = [(x['passage'], x['question']) for x in data]\n",
    "processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better, older, worse, smarter, taller, younger, different, more, stronger, bigger, shorter, less, tougher, cooler, faster, nicer, other, darker, hotter, smaller, happier, larger, wiser, richer, weaker, greater, higher, longer, harder, safer, closer, heavier, slower, easier, colder, thinner, quicker, thicker, deeper, quieter, lower, healthier, stranger, louder, cleaner, brighter, lighter, cheaper, newer, simpler, warmer, wealthier, poorer, sharper, wider, smoother, clearer, softer, superior, stricter\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('{first_name} is {bert} than {first_name2}.')[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 198 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb100e7061b4f70bbefd2c63ec45739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      198\n",
      "Fails (rate):    158 (79.8%)\n",
      "\n",
      "Example fails:\n",
      "C: Jessica is cleaner than Joshua.\n",
      "Q: Who is less clean?\n",
      "A: Jessica\n",
      "P: Joshua\n",
      "\n",
      "----\n",
      "C: Olivia is cooler than Heather.\n",
      "Q: Who is less cool?\n",
      "A: Olivia\n",
      "P: Heather\n",
      "\n",
      "----\n",
      "C: Justin is nicer than William.\n",
      "Q: Who is less nice?\n",
      "A: Justin\n",
      "P: William\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = map(list, zip(*(editor.template(\n",
    "    ((\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    ),\n",
    "    '{first_name}',\n",
    "    ),\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))))\n",
    "test = MFT(data, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs + [(x[1], x[0]) for x in comp_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 199 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865eef5c83c64dfd886329a01b368e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      199\n",
      "Fails (rate):    120 (60.3%)\n",
      "\n",
      "Example fails:\n",
      "C: Emma is slower than Jennifer.\n",
      "Q: Who is faster?\n",
      "A: Emma\n",
      "P: Jennifer\n",
      "\n",
      "----\n",
      "C: William is smaller than Kyle.\n",
      "Q: Who is bigger?\n",
      "A: William\n",
      "P: Kyle\n",
      "\n",
      "----\n",
      "C: Christian is stronger than Brittany.\n",
      "Q: Who is weaker?\n",
      "A: Christian\n",
      "P: Brittany\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = map(list, zip(*(editor.template(\n",
    "    ((\n",
    "    '{first_name} is {comp[0]} than {first_name1}.',\n",
    "    'Who is {comp[1]}?'\n",
    "    ),\n",
    "    '{first_name}',\n",
    "    ),\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))))\n",
    "test = MFT(data, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very, extremely, quite, also, not, pretty, really, still, more, incredibly, particularly, clearly, so, now, highly, already, rather, fairly, most, certainly, being, definitely, super, increasingly, especially, generally, actually, reportedly, apparently, understandably\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {bert} about the project.')[:20]\n",
    "print(', '.join(editor.suggest('John is {bert} {state} about the project.', state=state)[:30]))\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datalabels(templates, nsamples=None):\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "    for x in templates:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    return ret, ret_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2376 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f00b23365fa46a381aa4ce2ec8ca794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=297.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      198\n",
      "Fails (rate):    180 (90.9%)\n",
      "\n",
      "Example fails:\n",
      "C: Jonathan is serious about the project. Charles is very serious about the project.\n",
      "Q: Who is least serious about the project?\n",
      "A: Jonathan\n",
      "P: Charles\n",
      "\n",
      "\n",
      "----\n",
      "C: Samantha is confident about the project. Kyle is very confident about the project.\n",
      "Q: Who is least confident about the project?\n",
      "A: Samantha\n",
      "P: Kyle\n",
      "\n",
      "C: Samantha is somewhat confident about the project. Kyle is very confident about the project.\n",
      "Q: Who is least confident about the project?\n",
      "A: Samantha\n",
      "P: Kyle\n",
      "\n",
      "\n",
      "----\n",
      "C: Brandon is pessimistic about the project. Zachary is particularly pessimistic about the project.\n",
      "Q: Who is least pessimistic about the project?\n",
      "A: Brandon\n",
      "P: Zachary\n",
      "\n",
      "C: Zachary is pessimistic about the project. Brandon is somewhat pessimistic about the project.\n",
      "Q: Who is least pessimistic about the project?\n",
      "A: Brandon\n",
      "P: Zachary\n",
      "\n",
      "C: Brandon is somewhat pessimistic about the project. Zachary is pessimistic about the project.\n",
      "Q: Who is most pessimistic about the project?\n",
      "A: Zachary\n",
      "P: Brandon\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))\n",
    "test = MFT(data, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, chape, color, age, material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light, wall, table, object, couch, door, sofa, chair, mirror, box, window, clock, bar, elephant, lamp, carpet, curtain, room, bed, ball, spot, building, hole, stone, screen, candle, tree, cat, square, painting\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('There is {a:p.v1} {p.v2} {bert} in the room.', p=props, verbose=False)[:30]))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 800 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acff71e6a8624f86b783fe4c99413985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      200\n",
      "Fails (rate):    166 (83.0%)\n",
      "\n",
      "Example fails:\n",
      "C: There is a thing in the room. The thing is enormous and oval.\n",
      "Q: What size is the thing?\n",
      "A: enormous\n",
      "P: enormous and oval\n",
      "\n",
      "\n",
      "----\n",
      "C: There is a round purple clock in the room.\n",
      "Q: What shape is the clock?\n",
      "A: round\n",
      "P: round purple\n",
      "\n",
      "C: There is a clock in the room. The clock is round and purple.\n",
      "Q: What shape is the clock?\n",
      "A: round\n",
      "P: round and purple\n",
      "\n",
      "\n",
      "----\n",
      "C: There is a tiny black object in the room.\n",
      "Q: What size is the object?\n",
      "A: tiny\n",
      "P: tiny black\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))\n",
    "test = MFT(data, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:bert}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:bert}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985e420864c543b494af969c42d3b5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    51 (51.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Danielle is a Russian author.\n",
      "Q: What is Danielle's job?\n",
      "A: author\n",
      "P: Russian author\n",
      "\n",
      "\n",
      "----\n",
      "C: Emily is a Brazilian consultant.\n",
      "Q: What is Emily's job?\n",
      "A: consultant\n",
      "P: Brazilian consultant\n",
      "\n",
      "\n",
      "----\n",
      "C: Elizabeth is a Russian salesman.\n",
      "Q: What is Elizabeth's job?\n",
      "A: salesman\n",
      "P: Russian salesman\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal vs vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 400 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458bf84f6ecc4602aff6c64f62f28ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      100\n",
      "Fails (rate):    21 (21.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Michael has a bull and a train.\n",
      "Q: What vehicle does Michael have?\n",
      "A: train\n",
      "P: a bull and a train\n",
      "\n",
      "C: Michael has a train and a bull.\n",
      "Q: What vehicle does Michael have?\n",
      "A: train\n",
      "P: a train and a bull\n",
      "\n",
      "\n",
      "----\n",
      "C: Michael has a bull and a tractor.\n",
      "Q: What animal does Michael have?\n",
      "A: bull\n",
      "P: a bull and a tractor\n",
      "\n",
      "C: Michael has a bull and a tractor.\n",
      "Q: What vehicle does Michael have?\n",
      "A: tractor\n",
      "P: a bull and a tractor\n",
      "\n",
      "C: Michael has a tractor and a bull.\n",
      "Q: What animal does Michael have?\n",
      "A: bull\n",
      "P: a tractor and a bull\n",
      "\n",
      "\n",
      "----\n",
      "C: Alexander has a cow and a tractor.\n",
      "Q: What vehicle does Alexander have?\n",
      "A: tractor\n",
      "P: a cow and a tractor\n",
      "\n",
      "C: Alexander has a tractor and a cow.\n",
      "Q: What animal does Alexander have?\n",
      "A: cow\n",
      "P: a tractor and a cow\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 600 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3a5e7bcf444e6381ad1564f56ae25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      300\n",
      "Fails (rate):    46 (15.3%)\n",
      "\n",
      "Example fails:\n",
      "C: Tesla gained experience in telephony and electrical engineering before emigrating to the United States in 1884 to work for Thomas Edison in New York City. He soon struck out on his own with financial backers, setting up laboratories and companies to develop a range of electrical devices. His patented AC induction motor and transformer were licensed by George Westinghouse, who also hired Tesla for a short time as a consultant. His work in the formative years of electric power development was involved in a corporate alternating current/direct current \"War of Currents\" as well as various patent battles.\n",
      "Q: Where did Tesla work with Edison?\n",
      "P: New York City\n",
      "\n",
      "C: Tesla gained experience in telephony and electrical engineering before emigrating to the United States in 1884 to work for Thomas Edison in New York City. He soon struck out on his own with financial backers, setting up laboratories and companies to develop a range of electrical devices. His patented AC induction motor and transformer were licensed by George Westinghouse, who also hired Tesla for a short time as a consultant. His work in the formative years of electric power development was involved in a corporate alternating current/direct current \"War of Currents\" as well as various patent battles.\n",
      "Q: Whree did Tesla work with Edison?\n",
      "P: 1884 to work for Thomas Edison in New York City\n",
      "\n",
      "\n",
      "----\n",
      "C: Internet2 is a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government. The Internet2 community, in partnership with Qwest, built the first Internet2 Network, called Abilene, in 1998 and was a prime investor in the National LambdaRail (NLR) project. In 2006, Internet2 announced a partnership with Level 3 Communications to launch a brand new nationwide network, boosting its capacity from 10 Gbit/s to 100 Gbit/s. In October, 2007, Internet2 officially retired Abilene and now refers to its new, higher capacity network as the Internet2 Network.\n",
      "Q: Who did internet2 partner with \n",
      "P: Level 3 Communications\n",
      "\n",
      "C: Internet2 is a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government. The Internet2 community, in partnership with Qwest, built the first Internet2 Network, called Abilene, in 1998 and was a prime investor in the National LambdaRail (NLR) project. In 2006, Internet2 announced a partnership with Level 3 Communications to launch a brand new nationwide network, boosting its capacity from 10 Gbit/s to 100 Gbit/s. In October, 2007, Internet2 officially retired Abilene and now refers to its new, higher capacity network as the Internet2 Network.\n",
      "Q: Who di dinternet2 partner with \n",
      "P: Qwest\n",
      "\n",
      "\n",
      "----\n",
      "C: Tesla was a good friend of Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey. In middle age, Tesla became a close friend of Mark Twain; they spent a lot of time together in his lab and elsewhere. Twain notably described Tesla's induction motor invention as \"the most valuable patent since the telephone.\" In the late 1920s, Tesla also befriended George Sylvester Viereck, a poet, writer, mystic, and later, a Nazi propagandist. Tesla occasionally attended dinner parties held by Viereck and his wife.\n",
      "Q: Where did Tesla and Twain hang out?\n",
      "P: in his lab\n",
      "\n",
      "C: Tesla was a good friend of Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey. In middle age, Tesla became a close friend of Mark Twain; they spent a lot of time together in his lab and elsewhere. Twain notably described Tesla's induction motor invention as \"the most valuable patent since the telephone.\" In the late 1920s, Tesla also befriended George Sylvester Viereck, a poet, writer, mystic, and later, a Nazi propagandist. Tesla occasionally attended dinner parties held by Viereck and his wife.\n",
      "Q: Where did Tesla nad Twain hang out?\n",
      "P: his lab\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def question_typo(x):\n",
    "    return (x[0], Perturb.add_typos(x[1]))\n",
    "data = Perturb.perturb(pairs, question_typo, nsamples=300)\n",
    "test = INV(data)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      300\n",
      "Fails (rate):    14 (4.7%)\n",
      "\n",
      "Example fails:\n",
      "Q: If someone is being taught at their place of residence, what is it called?\n",
      "P: Informal learning\n",
      "\n",
      "Q: If someone is being taught at their place of residence, what's it called?\n",
      "P: home schooling\n",
      "\n",
      "\n",
      "----\n",
      "Q: How did Celeron handle meeting with Old Briton?\n",
      "P: threatened \"Old Briton\" with severe consequences\n",
      "\n",
      "Q: How'd Celeron handle meeting with Old Briton?\n",
      "P: Céloron threatened \"Old Briton\" with severe consequences\n",
      "\n",
      "\n",
      "----\n",
      "Q: Where did the discharge from glaciers go in Europe in the last Ice Age?\n",
      "P: the Rhine\n",
      "\n",
      "Q: Where'd the discharge from glaciers go in Europe in the last Ice Age?\n",
      "P: the Rhine and its downstream extension\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def contractions(x):\n",
    "    conts = Perturb.contractions(x[1])\n",
    "    return [(x[0], a) for a in conts]\n",
    "data = Perturb.perturb(pairs, contractions, nsamples=300)\n",
    "test = INV(data)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = set()\n",
    "for x, _ in processed_pairs:\n",
    "    for y in x.sents:\n",
    "        random_sentences.add(y.text)\n",
    "random_sentences = list(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " 'add to end: Later in the summer, Kenyatta visited China at the invitation of President Xi Jinping after a stop in Russia and not having visited the United States as president. ',\n",
       " 'add to beg: Later in the summer, Kenyatta visited China at the invitation of President Xi Jinping after a stop in Russia and not having visited the United States as president. ']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      300\n",
      "Fails (rate):    18 (6.0%)\n",
      "\n",
      "Example fails:\n",
      "Q: What do most online pharmacies do?\n",
      "P: sell prescription drugs\n",
      "\n",
      "Q: What do most online pharmacies do?\n",
      "P: sell prescription drugs and require a valid prescription\n",
      "Perturb: add to beg: In 2005 it moved to a new facility on The Watermark business park next to the MetroCentre in Gateshead. \n",
      "\n",
      "\n",
      "----\n",
      "Q: Concrete bounding of computation time frequently produces complexity classes contingent upon what?\n",
      "P: the chosen machine model\n",
      "\n",
      "Q: Concrete bounding of computation time frequently produces complexity classes contingent upon what?\n",
      "P: machine model\n",
      "Perturb: add to end: Many important complexity classes can be defined by bounding the time or space used by the algorithm. \n",
      "\n",
      "\n",
      "----\n",
      "Q: What is formed when a phagosome fuses with a lysosome?\n",
      "P: a phagolysosome\n",
      "\n",
      "Q: What is formed when a phagosome fuses with a lysosome?\n",
      "P: phagolysosome\n",
      "Perturb: add to beg: One of the most important pieces in this collection is a marquetry commode by the ébéniste Jean Henri Riesener dated c1780. \n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "def add_random_sentence(x):\n",
    "    random_s = np.random.choice(random_sentences)\n",
    "    while random_s in x[0]:\n",
    "        random_s = np.random.choice(random_sentences)\n",
    "    random_s = random_s.strip('.') + '. '\n",
    "    meta = ['add to end: %s' % random_s, 'add to beg: %s' % random_s]\n",
    "    return [(x[0] + random_s, x[1]), (random_s + x[0], x[1])], meta\n",
    "\n",
    "def format_add(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "data, meta = Perturb.perturb(pairs, add_random_sentence, nsamples=300, returns_meta=True)\n",
    "test = INV(data, meta=meta)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_add)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 192 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a371674a317b4064af716d6d2d34c3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      96\n",
      "Fails (rate):    44 (45.8%)\n",
      "\n",
      "Example fails:\n",
      "C: Both Nicole and Austin were cleaners, but there was a change in Nicole, who is now a musician.\n",
      "Q: Who is a musician?\n",
      "A: Nicole\n",
      "P: Nicole and Austin were cleaners, but there was a change in Nicole\n",
      "\n",
      "\n",
      "----\n",
      "C: Both Emma and Hannah were DJs, but there was a change in Hannah, who is now a photographer.\n",
      "Q: Who is a photographer?\n",
      "A: Hannah\n",
      "P: Hannah were DJs, but there was a change in Hannah\n",
      "\n",
      "\n",
      "----\n",
      "C: Both Sara and Dylan were psychologists, but there was a change in Sara, who is now an artist.\n",
      "Q: Who is an artist?\n",
      "A: Sara\n",
      "P: Sara and Dylan were psychologists, but there was a change in Sara\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 392 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087f52c65e5245b59a357310366204b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      98\n",
      "Fails (rate):    82 (83.7%)\n",
      "\n",
      "Example fails:\n",
      "C: Jose became a analyst after Richard did.\n",
      "Q: Who became a analyst last?\n",
      "A: Jose\n",
      "P: Richard\n",
      "\n",
      "\n",
      "----\n",
      "C: Danielle became a historian before James did.\n",
      "Q: Who became a historian last?\n",
      "A: James\n",
      "P: Danielle\n",
      "\n",
      "\n",
      "----\n",
      "C: Aaron became a actress before Jeremy did.\n",
      "Q: Who became a actress last?\n",
      "A: Jeremy\n",
      "P: Aaron\n",
      "\n",
      "C: Jeremy became a actress after Aaron did.\n",
      "Q: Who became a actress first?\n",
      "A: Aaron\n",
      "P: Jeremy\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 792 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0855a1716f7e44fa800d4bc6d9a3a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      198\n",
      "Fails (rate):    153 (77.3%)\n",
      "\n",
      "Example fails:\n",
      "C: Kelly is not an investigator. Sophia is.\n",
      "Q: Who is an investigator?\n",
      "A: Sophia\n",
      "P: Kelly\n",
      "\n",
      "\n",
      "----\n",
      "C: Stephanie is a model. Christian is not.\n",
      "Q: Who is not a model?\n",
      "A: Christian\n",
      "P: Stephanie\n",
      "\n",
      "\n",
      "----\n",
      "C: Jacob is an artist. Katherine is not.\n",
      "Q: Who is not an artist?\n",
      "A: Katherine\n",
      "P: Jacob\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=200,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 776 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0508fa8657f34889887f7c1a233d4696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      97\n",
      "Fails (rate):    97 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Andrea is a doctor. Amy is a DJ.\n",
      "Q: Who is not a doctor?\n",
      "A: Amy\n",
      "P: Andrea\n",
      "\n",
      "C: Andrea is a doctor. Amy is a DJ.\n",
      "Q: Who is not a DJ?\n",
      "A: Andrea\n",
      "P: Amy\n",
      "\n",
      "C: Amy is a DJ. Andrea is a doctor.\n",
      "Q: Who is not a doctor?\n",
      "A: Amy\n",
      "P: Andrea\n",
      "\n",
      "\n",
      "----\n",
      "C: Isabella is an advisor. Jacob is a chef.\n",
      "Q: Who is not an advisor?\n",
      "A: Jacob\n",
      "P: Isabella\n",
      "\n",
      "C: Isabella is an advisor. Jacob is a chef.\n",
      "Q: Who is not a chef?\n",
      "A: Isabella\n",
      "P: Jacob\n",
      "\n",
      "C: Jacob is a chef. Isabella is an advisor.\n",
      "Q: Who is not an advisor?\n",
      "A: Jacob\n",
      "P: Isabella\n",
      "\n",
      "\n",
      "----\n",
      "C: Anthony is an architect. Noah is an educator.\n",
      "Q: Who is not an architect?\n",
      "A: Noah\n",
      "P: Anthony\n",
      "\n",
      "C: Anthony is an architect. Noah is an educator.\n",
      "Q: Who is not an educator?\n",
      "A: Anthony\n",
      "P: Noah\n",
      "\n",
      "C: Noah is an educator. Anthony is an architect.\n",
      "Q: Who is not an architect?\n",
      "A: Noah\n",
      "P: Anthony\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness spinoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin           fail_men fail_women (count)\n",
      "doctor          0.02      0.85     (104)\n",
      "nurse           0.56      0.41     (90)\n",
      "secretary       0.54      0.08     (106)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profession    fail_men fail_women (count)\n",
      "doctor          0.03      0.87     (173)\n",
      "secretary       0.62      0.02     (165)\n",
      "nurse           0.61      0.35     (162)\n"
     ]
    }
   ],
   "source": [
    "# fewer_profs = ['doctor', 'nurse', 'secretary']\n",
    "datameta = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "    prof=professions,\n",
    "#     prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=10000,\n",
    "    unroll=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in datameta]\n",
    "labels = [d[2] for d in datameta]\n",
    "meta = [(d[3], d[4]) for d in datameta]\n",
    "\n",
    "test = MFT(data, expect=expect_squad, labels=labels, meta=meta)\n",
    "test.run(new_pp)\n",
    "\n",
    "def print_fair(test):\n",
    "    c = collections.Counter(test.meta)\n",
    "    fail = collections.Counter([tuple(x) for x in np.array(test.meta)[test.fail_idxs()]])\n",
    "    profs = set()\n",
    "    for sex, prof in fail:\n",
    "        profs.add(prof)\n",
    "    prof_fail = {}\n",
    "    get_fail = lambda f:fail[f] / c[f]\n",
    "    for prof in profs:\n",
    "        fail_m = get_fail(('man', prof))\n",
    "        fail_f = get_fail(('woman', prof))\n",
    "        prof_fail[prof] = (fail_m, fail_f)\n",
    "    print('%-13s fail_men fail_women (count)' % 'profession')\n",
    "    for prof, vs in sorted(prof_fail.items(), key=lambda x:max(x[1][0], x[1][1]), reverse=True):\n",
    "        fail_m, fail_f = vs\n",
    "        print('%-13s   %.2f      %.2f     (%d)' % (prof, fail_m, fail_f, c[('man', prof)]))\n",
    "print_fair(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 784 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cec1906f31c435c93c06cf5256d0a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=98.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      98\n",
      "Fails (rate):    98 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Nathan and Andrea are friends. He is an entrepreneur, and she is an agent.\n",
      "Q: Who is an entrepreneur?\n",
      "A: Nathan\n",
      "P: Nathan and Andrea\n",
      "\n",
      "C: Andrea and Nathan are friends. He is an entrepreneur, and she is an agent.\n",
      "Q: Who is an agent?\n",
      "A: Andrea\n",
      "P: Nathan\n",
      "\n",
      "C: Nathan and Andrea are friends. She is an agent, and he is an entrepreneur.\n",
      "Q: Who is an entrepreneur?\n",
      "A: Nathan\n",
      "P: Andrea\n",
      "\n",
      "\n",
      "----\n",
      "C: Richard and Natalie are friends. He is a waitress, and she is a photographer.\n",
      "Q: Who is a waitress?\n",
      "A: Richard\n",
      "P: Natalie\n",
      "\n",
      "C: Natalie and Richard are friends. He is a waitress, and she is a photographer.\n",
      "Q: Who is a photographer?\n",
      "A: Natalie\n",
      "P: Richard\n",
      "\n",
      "C: Richard and Natalie are friends. She is a photographer, and he is a waitress.\n",
      "Q: Who is a waitress?\n",
      "A: Richard\n",
      "P: Natalie\n",
      "\n",
      "\n",
      "----\n",
      "C: Ashley and Gabriel are friends. He is a psychologist, and she is a model.\n",
      "Q: Who is a model?\n",
      "A: Ashley\n",
      "P: Gabriel\n",
      "\n",
      "C: Gabriel and Ashley are friends. She is a model, and he is a psychologist.\n",
      "Q: Who is a psychologist?\n",
      "A: Gabriel\n",
      "P: Ashley\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Former, latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 396 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      99\n",
      "Fails (rate):    99 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Jonathan and Jeremy are friends. The former is a photographer.\n",
      "Q: Who is a photographer?\n",
      "A: Jonathan\n",
      "P: Jeremy\n",
      "\n",
      "C: Jonathan and Jeremy are friends. The former is a photographer and the latter is a producer.\n",
      "Q: Who is a photographer?\n",
      "A: Jonathan\n",
      "P: Jonathan and Jeremy\n",
      "\n",
      "\n",
      "----\n",
      "C: Steven and Benjamin are friends. The former is a therapist.\n",
      "Q: Who is a therapist?\n",
      "A: Steven\n",
      "P: Benjamin\n",
      "\n",
      "C: Steven and Benjamin are friends. The former is a therapist and the latter is a salesman.\n",
      "Q: Who is a therapist?\n",
      "A: Steven\n",
      "P: Benjamin\n",
      "\n",
      "\n",
      "----\n",
      "C: Kimberly and Katherine are friends. The former is a cleaner.\n",
      "Q: Who is a cleaner?\n",
      "A: Kimberly\n",
      "P: Katherine\n",
      "\n",
      "C: Kimberly and Katherine are friends. The former is a cleaner and the latter is an investigator.\n",
      "Q: Who is a cleaner?\n",
      "A: Kimberly\n",
      "P: Kimberly and Katherine\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 392 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5bebfe05e6417ebd73fce0503e7a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      98\n",
      "Fails (rate):    54 (55.1%)\n",
      "\n",
      "Example fails:\n",
      "C: Samantha supports Michael.\n",
      "Q: Who is supported?\n",
      "A: Michael\n",
      "P: Samantha supports Michael\n",
      "\n",
      "C: Michael is supported by Samantha.\n",
      "Q: Who is supported?\n",
      "A: Michael\n",
      "P: Samantha\n",
      "\n",
      "\n",
      "----\n",
      "C: Scott supports Danielle.\n",
      "Q: Who is supported?\n",
      "A: Danielle\n",
      "P: Scott\n",
      "\n",
      "\n",
      "----\n",
      "C: Sophia trusts Kyle.\n",
      "Q: Who trusts?\n",
      "A: Sophia\n",
      "P: Sophia trusts Kyle\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import pattern\n",
    "import pattern.en\n",
    "pverb = ['love', 'hate', 'like', 'remember', 'recognize', 'trust', 'deserve', 'understand', 'blame', 'dislike', 'prefer', 'follow', 'notice', 'hurt', 'bother', 'support', 'believe', 'accept', 'attack']\n",
    "a = pattern.en.tenses('loves')[0]\n",
    "b = pattern.en.tenses('stolen')[0]\n",
    "pverb = [(pattern.en.conjugate(v, *a), pattern.en.conjugate(v, *b)) for v in pverb]\n",
    "\n",
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1568 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de7346a2035471eb21a940c43fd9969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cases:      98\n",
      "Fails (rate):    92 (93.9%)\n",
      "\n",
      "Example fails:\n",
      "C: Sophia accepts Joseph. Zachary is accepted by Joseph.\n",
      "Q: Who accepts Zachary?\n",
      "A: Joseph\n",
      "P: Sophia accepts Joseph\n",
      "\n",
      "\n",
      "----\n",
      "C: Kelly understands Ethan. Nathan is understood by Ethan.\n",
      "Q: Who understands Nathan?\n",
      "A: Ethan\n",
      "P: Kelly\n",
      "\n",
      "C: Kelly understands Ethan. Nathan is understood by Ethan.\n",
      "Q: Who is understood by Kelly?\n",
      "A: Ethan\n",
      "P: Nathan\n",
      "\n",
      "\n",
      "----\n",
      "C: Erin follows Jose. Michael is followed by Jose.\n",
      "Q: Who is followed by Erin?\n",
      "A: Jose\n",
      "P: Jose. Michael\n",
      "\n",
      "C: Jose is followed by Erin. Jose follows Michael.\n",
      "Q: Who is followed by Jose?\n",
      "A: Michael\n",
      "P: Erin\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data, labels = to_datalabels(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]} {first_name2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who {v[0]} {first_name3}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name2}?',\n",
    "                '{first_name3}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    "    ))\n",
    "test = MFT(data, expect=expect_squad, labels=labels)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
