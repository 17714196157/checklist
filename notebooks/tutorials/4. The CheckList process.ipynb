{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the [paper](https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf), you know that CheckList is more than this package, it's also a process.  \n",
    "This tutorial is a short version of that process, but you should really read the paper if you haven't :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Model: QQP, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we'll use Quora Question Pair as an example, and I'm running a finetuned BERT model in a server.  \n",
    "The details below are not important, but are necessary for me to run the rest of the notebook. You won't be able to run them, but you can substitute your own model here if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "import sys\n",
    "import spacy\n",
    "import numpy as np\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import model_wrapper\n",
    "model = model_wrapper.ModelWrapper()\n",
    "new_pp = PredictorWrapper.wrap_softmax(model.predict_proba)\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\tWhat does the Quran say about homosexuality?\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qs = []\n",
    "labels = []\n",
    "all_questions = set()\n",
    "for x in open('/home/marcotcr/datasets/glue/glue_data/QQP/dev.tsv').readlines()[1:]:\n",
    "    try:\n",
    "        q1, q2, label = x.strip().split('\\t')[3:]\n",
    "    except:\n",
    "        print(x)\n",
    "        continue\n",
    "    all_questions.add(q1)\n",
    "    all_questions.add(q2)\n",
    "    qs.append((q1, q2))\n",
    "    labels.append(label)\n",
    "labels = np.array(labels).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset preprocessed by spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_qqp.pkl', 'rb'))\n",
    "parsed_qs = [(spacy_map[q[0]], spacy_map[q[1]]) for q in qs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-Down approach: the CheckList matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capabilities x Test Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial #3, we talked about specific test types.  \n",
    "In order to guide test ideation, it's useful to think of CheckList as a matrix of Capabilities x Test Types.  \n",
    "*Capabilities* refers to general-purpose linguistic capabilities, which manifest in one way or another in almost any NLP application.   \n",
    "We suggest that anyone CheckListing a model go through *at least* the following capabilities, trying to create MFTs, INVs, and DIRs for each if possible.\n",
    "1. **Vocabulary + POS:** important words or groups of words (by part-of-speech) for the task\n",
    "2. **Taxonomy**: synonyms, antonyms, word categories, etc\n",
    "3. **Robustness**: to typos, irrelevant additions, contractions, etc\n",
    "4. **Named Entity Recognition (NER)**: person names, locations, numbers, etc\n",
    "5. **Fairness**\n",
    "6. **Temporal understanding**: understanding order of events and how they impact the task\n",
    "7. **Negation**\n",
    "8. **Coreference** \n",
    "9. **Semantic Role Labeling (SRL)**: understanding roles such as agent, object, passive/active, etc\n",
    "10. **Logic**: symmetry, consistency, conjunctions, disjunctions, etc\n",
    "\n",
    "Notice that we are framing this as very top-down approach: you start with a list of capabilities and try to think of what kinds of tests can be created. We'll talk about how to incorporate some bottom-up thinking later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't try to create tests for **all** of these capabilities (but we do have notebooks with tests for all of them in the repo), just one as an example. \n",
    "Anyway, let's create a test suite (used to aggregate tests and save them for later use):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the NER capability.  \n",
    "How do named entities impact duplicate question detection? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFT\n",
    "It seems that the model should at least be able to distinguish questions about different people as non-duplicates.   \n",
    "Let's write an MFT where we have two people that have the same last name, but different first names.  \n",
    "Instead of running the test now, we'll add it to the suite and run all tests later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template((\n",
    "    'Is {first_name} {last_name} {mask}?',\n",
    "    'Is {first_name2} {last_name} {mask}?',\n",
    "    ),\n",
    "#     adj=adjs_without_overlap,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "test = MFT(**t, labels=0, name='same adjectives, different people', capability = 'NER',\n",
    "          description='Different first name, same adjective and last name')\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=5)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INV\n",
    "If you have two questions with the same named entity, changing the entity on both should not change whether the questions are duplicates or not.  \n",
    "Let's write an INV for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with pairs of questions, we have to write a wrapper to make sure the same name is changed on both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_both(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    # separating out examples and meta. Meta has tuples (a, b), where name 'a' was changed to 'b'\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    # Only include examples where the same name was changed on both questions\n",
    "    return [(q1, q2) for q1, q2, m1, m2 in zip(c1, c2, m1, m2) if m1 == m2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_both, nsamples=200)\n",
    "test = INV(**t, name='Change same name in both questions', capability='NER',\n",
    "          description='')\n",
    "# test.run(new_pp)\n",
    "# test.summary(3)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIR\n",
    "Conversely, if an entity is present on a pair the model predicts as a duplicate and we change it to something else on *only one* of the sentences, the prediction should change to non-duplicate.  \n",
    "Let's write this as a DIR test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_one(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    ret = []\n",
    "    ret.extend([(q1_, str(q2)) for q1_, m1_ in zip(c1, m1) if m1_[0] in str(q2)])\n",
    "    ret.extend([(str(q1), q2_) for q2_, m2_ in zip(c2, m2) if m2_[0] in str(q1)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write an expectation function in two steps.  \n",
    "First, we want the prediction to be 0.  \n",
    "Second, we only want to include examples where the original prediction is one. We do this with a slice wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_fn = Expect.eq(0)\n",
    "expect_fn = Expect.slice_orig(expect_fn, lambda orig, *args: orig == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together into a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_one, nsamples=200)\n",
    "name = 'Change name in one of the questions'\n",
    "desc = 'Take pairs that are originally predicted as duplicates, change name in one of them and expect new prediction to be non-duplicate'\n",
    "test = DIR(**t, expect=expect_fn, name=name, description=desc, capability='NER')\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples illustrate how thinking through the matrix can help test ideation. We now turn to a bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we look at specific examples (from the validation dataset or elsewhere) and try to generalize them into MFTs, INVs or DIRs, placing them into a specific capability.  \n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Which company should I join as a fresher, TCS or Virtusa?',\n",
       " 'Is it a good decision to join Tcs as a fresher?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(14)\n",
    "i = np.random.choice(len(qs))\n",
    "qs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example, in which a question asks about a comparison between two options, while the other question asks about a single option.  \n",
    "While they are not duplicates, it is possible that models would get confused here. I think this test fits into the Vocabulary+POS capability (it's not crucial for us to be completely precise about where a test fits).  \n",
    "Let's try to create an MFT out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple, Google, Facebook, This, Microsoft, Amazon, Uber, It, Intel, Samsung, Netflix, Tesla, Twitter, LinkedIn, Oracle, Target, Snap, Disney, AMD, Bloomberg, Sony, That, Wikipedia, China, Here, Fox, this, HP, FB, YouTube, Reddit, Ford, Pinterest, Harris, MIT, GE, CBS, Dialog, Square, Orange'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(editor.suggest('{mask} is a large tech company.')[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['Apple', 'Google', 'Facebook', 'Microsoft', 'Amazon', 'Uber', 'Intel', 'Samsung', 'Netflix', 'Tesla', 'LinkedIn', 'Oracle', 'Target', 'Snap', 'Disney', 'AMD', 'Sony', 'Reddit', 'Youtube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'customer, shareholder, developer, member, contributor, competitor, CEO, volunteer, writer, buyer, contractor, professional, student, director, consumer, manager, result, whole, rookie, client, refugee, sponsor, person, seller, consultant, subscriber, user, beta, startup, citizen'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(editor.suggest('Should I join {company} as a {mask}?', company=companies)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = ['developer', 'contributor', 'freshman', 'college grad', 'volunteer', 'writer', 'contractor', 'consultant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Which company should I join as a contributor, Samsung or Facebook?',\n",
       "  'Should I join Samsung as a contributor?'),\n",
       " ('Which company should I join as a volunteer, LinkedIn or Sony?',\n",
       "  'Should I join LinkedIn as a volunteer?'),\n",
       " ('Which company should I join as a consultant, Disney or Apple?',\n",
       "  'Should I join Disney as a consultant?')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = editor.template((\n",
    "       'Which company should I join as a {role}, {company1} or {company2}?',\n",
    "       'Should I join {company1} as a {role}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    role=role,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    ")\n",
    "t.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replicated the original example, but we can generalize it a bit to other comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('efforts', 'succeed'), ('strategy', 'work'), ('dominance', 'continue'), ('efforts', 'work'), ('plan', 'work'), ('strategy', 'working'), ('dominance', 'end'), ('experiment', 'work'), ('attempts', 'succeed'), ('approach', 'work'), ('success', 'continue'), ('tactics', 'work'), ('strategy', 'succeed'), ('experiment', 'succeed'), ('strategy', 'stick'), ('gamble', 'succeed'), ('gamble', 'work'), ('strategy', 'continue'), ('dominance', 'last'), ('strategy', 'worked'), ('dominance', 'sustainable'), ('crackdown', 'work'), ('plans', 'work'), ('efforts', 'continue'), ('decision', 'stick'), ('plan', 'succeed'), ('growth', 'continue'), ('experiments', 'work'), ('decision', 'stand'), ('strategy', 'change'), ('effort', 'succeed'), ('efforts', 'working'), ('attempts', 'work'), ('domination', 'continue'), ('move', 'work'), ('strategies', 'work'), ('lawsuit', 'succeed'), ('efforts', 'successful'), ('methods', 'work'), ('policies', 'change'), ('dominance', 'over'), ('strategy', 'stuck'), ('focus', 'change'), ('ambitions', 'succeed'), ('future', 'lie'), ('plans', 'succeed'), ('intentions', 'change'), ('success', 'sustainable'), ('strategy', 'fail'), ('ban', 'stand')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([str(x) for x in editor.suggest('Will Google\\'s {mask} {mask}?')][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Which company's stock will rise later, Microsoft or Sony?\",\n",
       "  \"Will Microsoft's stock rise?\"),\n",
       " (\"Which company's board will resign most, Disney or Sony?\",\n",
       "  \"Will Disney's board resign?\"),\n",
       " (\"Which company's focus will change sooner, Microsoft or LinkedIn?\",\n",
       "  \"Will Microsoft's focus change?\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t += editor.template((\n",
    "       'Which company\\'s {fverb[0]} will {fverb[1]} {comp}, {company1} or {company2}?',\n",
    "       'Will {company1}\\'s {fverb[0]} {fverb[1]}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    comp=['most', 'least', 'sooner', 'later'],\n",
    "    fverb=[('stock', 'rise'), ('CEO', 'quit'), ('board', 'resign'), ('stock', 'fall'), ('effort', 'succeed'), ('strategy', 'work'), ('plan', 'work'), ('gamble', 'work'), ('focus', 'change'), ('intentions', 'change')],\n",
    "    nsamples=300,\n",
    "    remove_duplicates=True,\n",
    ")\n",
    "t.data[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MFT(**t, labels=0, name='Comparison between two entities is not the same as asking about one', capability = 'Vocabulary',\n",
    "          description='')\n",
    "suite.add(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the suite, seeing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 377 examples\n",
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n",
      "Running same adjectives, different people\n",
      "Predicting 299 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2074 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3837 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(new_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      374\n",
      "Fails (rate):    1 (0.3%)\n",
      "\n",
      "Example fails:\n",
      "0.6 (\"Which company's board will resign sooner, Microsoft or Apple?\", \"Will Microsoft's board resign?\")\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      299\n",
      "Fails (rate):    23 (7.7%)\n",
      "\n",
      "Example fails:\n",
      "0.5 ('Is Daniel Bennett guilty?', 'Is Matthew Bennett guilty?')\n",
      "----\n",
      "0.8 ('Is Amber Price ill?', 'Is Ashley Price ill?')\n",
      "----\n",
      "0.8 ('Is Dylan Williams happy?', 'Is Justin Williams happy?')\n",
      "----\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    18 (9.0%)\n",
      "\n",
      "Example fails:\n",
      "0.7 ('Can Hillary Clinton be charged of perjury for not releasing the entirety of her emails?', \"Why hasn't Hillary Clinton been charged with perjury?\")\n",
      "0.0 ('Can Emily Parker be charged of perjury for not releasing the entirety of her emails?', \"Why hasn't Emily Parker been charged with perjury?\")\n",
      "0.0 ('Can Jessica Cox be charged of perjury for not releasing the entirety of her emails?', \"Why hasn't Jessica Cox been charged with perjury?\")\n",
      "\n",
      "----\n",
      "0.9 ('Is the word pussy no longer on the list of forbidden words? Do we have Donald Trump to thank for this?', 'Is the word p#ssy no longer on the list of forbidden words? Do we have Donald Trump to thank for this?')\n",
      "0.4 ('Is the word pussy no longer on the list of forbidden words? Do we have David Lewis to thank for this?', 'Is the word p#ssy no longer on the list of forbidden words? Do we have David Lewis to thank for this?')\n",
      "\n",
      "----\n",
      "0.0 (\"What if Adam and Eve didn't eat of the tree of good and evil?\", \"What if Adam and Eve didn't eat the apple?\")\n",
      "0.8 (\"What if Adam and Patricia didn't eat of the tree of good and evil?\", \"What if Adam and Patricia didn't eat the apple?\")\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "After filtering: 104 (52.0%)\n",
      "Fails (rate):    30 (28.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 ('Were Jews responsible for the killing of Jesus?', \"Are the Jews seen as responsible for Jesus' death?\")\n",
      "1.0 ('Were Jews responsible for the killing of Jesus?', \"Are the Jews seen as responsible for Alex' death?\")\n",
      "1.0 ('Were Jews responsible for the killing of Jesus?', \"Are the Jews seen as responsible for Christopher' death?\")\n",
      "\n",
      "----\n",
      "1.0 ('How can you determine the Lewis structure for sulfuric acid?', 'How is the Lewis structure of sulfuric acid determined?')\n",
      "0.7 ('How can you determine the William structure for sulfuric acid?', 'How is the Lewis structure of sulfuric acid determined?')\n",
      "0.7 ('How can you determine the Lewis structure for sulfuric acid?', 'How is the William structure of sulfuric acid determined?')\n",
      "\n",
      "----\n",
      "0.8 ('Is anyone willing to join Vajiram and Ravi for UPSC in 2017?', 'Is anyone joining Vajiram and Ravi for the upcoming July 2017 Batch?')\n",
      "0.9 ('Is anyone willing to join Vajiram and Ravi for UPSC in 2017?', 'Is anyone joining Vajiram and Jayden for the upcoming July 2017 Batch?')\n",
      "0.6 ('Is anyone willing to join Vajiram and Ravi for UPSC in 2017?', 'Is anyone joining Vajiram and Jack for the upcoming July 2017 Batch?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d33a1bfa2846d880ee5e6fb3ad68e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Comparison between t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: testing Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few additional tests for the Taxonomy capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('organised', 'organized', 'direct', 'engineer'), ('specific', 'particular'), ('mean', 'hateful', 'average'), ('important', 'authoritative', 'significant'), ('courageous', 'brave'), ('rude', 'primitive', 'crude'), ('dependent', 'qualified'), ('efficient', 'effective'), ('resilient', 'live'), ('free', 'liberal', 'innocent'), ('scared', 'frightened'), ('suspicious', 'suspect', 'wary'), ('tolerant', 'resistant', 'liberal', 'kind'), ('activist', 'militant'), ('thoughtful', 'attentive'), ('alienated', 'alien', 'estranged'), ('innovative', 'modern', 'advanced'), ('ethical', 'honorable'), ('enlightened', 'educated', 'clear'), ('emotional', 'excited'), ('positive', 'confident'), ('fat', 'productive', 'rich', 'fatty'), ('honest', 'reliable', 'good', 'fair', 'true', 'honorable'), ('so', 'then'), ('inspired', 'divine'), ('nervous', 'anxious'), ('radical', 'revolutionary'), ('capable', 'able', 'open'), ('knowledgeable', 'learned', 'intimate'), ('humble', 'modest', 'small'), ('grateful', 'thankful'), ('sensitive', 'sensible'), ('authentic', 'reliable'), ('fearful', 'cowardly', 'awful', 'terrible'), ('smart', 'wise', 'chic', 'bright'), ('worried', 'upset'), ('healthy', 'intelligent', 'sound', 'respectable'), ('confident', 'positive'), ('alone', 'solitary', 'lonely'), ('conservative', 'cautious'), ('desperate', 'heroic'), ('strict', 'rigid', 'stern'), ('fit', 'set'), ('depressed', 'blue'), ('frustrated', 'queer', 'defeated', 'disappointed'), ('demanding', 'exact'), ('independent', 'autonomous'), ('open', 'capable', 'clear', 'candid', 'receptive'), ('bad', 'sorry', 'tough', 'risky', 'spoiled', 'defective'), ('mindful', 'aware')\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.synonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        tmp.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(', '.join([str(tuple(x)) for x in tmp][:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of those, let's pick a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can create a simple MFT, where we expect the model to recognize these synonyms.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    (\n",
    "    'How can I become {moreless} {x[0]}?',\n",
    "    'How can I become {moreless} {x[1]}?',\n",
    "    ),\n",
    "    x=synonyms,\n",
    "    moreless=['more', 'less'],\n",
    "    remove_duplicates=True, \n",
    "    nsamples=200)\n",
    "name = 'How can I become more {synonym}?' \n",
    "desc = 'different (simple) templates where words are replaced with their synonyms'\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with antonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('specific', 'general'),('courageous', 'fearful'),('rude', 'civil', 'polite'),('dependent', 'independent'),('pessimistic', 'optimistic'),('emotional', 'intellectual'),('positive', 'negative', 'neutral'),('fat', 'lean', 'thin'),('capitalist', 'socialist'),('irresponsible', 'responsible'),('organic', 'functional'),('humble', 'proud'),('smart', 'stupid'),('visible', 'invisible'),('conservative', 'progressive', 'liberal'),('impatient', 'patient'),('bad', 'good'),('shy', 'confident'),('negative', 'positive'),('hungry', 'thirsty'),('stupid', 'smart', 'intelligent'),('unhappy', 'happy'),('religious', 'secular'),('insecure', 'secure'),('conspicuous', 'invisible'),('hopeful', 'hopeless'),('progressive', 'conservative'),('individual', 'common'),('defensive', 'offensive'),('optimistic', 'pessimistic'),('passive', 'active'),('powerless', 'powerful'),('cautious', 'brave'),('active', 'passive')\n"
     ]
    }
   ],
   "source": [
    "opps = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        opps.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(','.join([str(tuple(x)) for x in opps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template([(\n",
    "    'How can I become more {x[0]}?',\n",
    "    'How can I become less {x[1]}?',\n",
    "    ),\n",
    "    (\n",
    "    'How can I become less {x[0]}?',\n",
    "    'How can I become more {x[1]}?',\n",
    "    )],\n",
    "    unroll=True,\n",
    "    x=antonyms,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "name = 'How can I become more X = How can I become less antonym(X)' \n",
    "desc = ''\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easy to turn the synonym one into an INV as well (we do this in another notebook), but let's end here after we run the suite again and see new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n",
      "Running same adjectives, different people\n",
      "Predicting 296 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2034 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3861 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 378 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(new_pp, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      378\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    40 (20.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 ('How can I become more happy?', 'How can I become more joyful?')\n",
      "----\n",
      "0.0 ('How can I become less vocal?', 'How can I become less outspoken?')\n",
      "----\n",
      "0.0 ('How can I become less vocal?', 'How can I become less outspoken?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    405 (67.5%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become less humble?', 'How can I become more proud?')\n",
      "----\n",
      "0.0 ('How can I become more rude?', 'How can I become less polite?')\n",
      "----\n",
      "0.0 ('How can I become more hopeful?', 'How can I become less hopeless?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      296\n",
      "Fails (rate):    27 (9.1%)\n",
      "\n",
      "Example fails:\n",
      "0.8 ('Is Olivia Ramirez dead?', 'Is Victoria Ramirez dead?')\n",
      "----\n",
      "0.9 ('Is Amanda Adams fired?', 'Is Victoria Adams fired?')\n",
      "----\n",
      "1.0 ('Is Lauren White legit?', 'Is Alexis White legit?')\n",
      "----\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    25 (12.5%)\n",
      "\n",
      "Example fails:\n",
      "0.6 ('Why was Michael Collins in the space module orbiting the moon while Neil and Buzz were stepping onto the moon?', \"Why didn't Michael Collins step on the Moon?\")\n",
      "0.2 ('Why was John Lopez in the space module orbiting the moon while Neil and Buzz were stepping onto the moon?', \"Why didn't John Lopez step on the Moon?\")\n",
      "\n",
      "----\n",
      "1.0 ('What is your favourite memory of Carrie Fisher?', 'How will you remember Carrie Fisher?')\n",
      "0.2 ('What is your favourite memory of Nicole Perez?', 'How will you remember Nicole Perez?')\n",
      "0.3 ('What is your favourite memory of Elizabeth Thompson?', 'How will you remember Elizabeth Thompson?')\n",
      "\n",
      "----\n",
      "0.0 ('What stops Bernie Sanders from running as a Republican?', 'Why has Bernie Sanders stopped running?')\n",
      "0.9 ('What stops Daniel Myers from running as a Republican?', 'Why has Daniel Myers stopped running?')\n",
      "0.8 ('What stops William Perez from running as a Republican?', 'Why has William Perez stopped running?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "Fails (rate):    40 (20.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 ('Will Donald Trump or Hillary Clinton win the 2016 US presidential election?', 'Who will be the next president of USA: Hillary Clinton or Donald Trump?')\n",
      "1.0 ('Will Donald Trump or Hillary Clinton win the 2016 US presidential election?', 'Who will be the next president of USA: Hillary Clinton or Joshua Johnson?')\n",
      "0.9 ('Will Donald Trump or Hillary Clinton win the 2016 US presidential election?', 'Who will be the next president of USA: Hillary Clinton or Christopher Garcia?')\n",
      "\n",
      "----\n",
      "0.0 ('Who would be better for Pakistan, Donald Trump or Hillary Clinton?', 'Who is better for India: Donald Trump or Hillary Clinton?')\n",
      "0.6 ('Who would be better for Pakistan, Donald Trump or Elizabeth Johnson?', 'Who is better for India: Donald Trump or Hillary Clinton?')\n",
      "\n",
      "----\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Donald Trump in the 2016 Presidential election?')\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Daniel Smith in the 2016 Presidential election?')\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Joshua Johnson in the 2016 Presidential election?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2cfd61785244bdac7db69aa5258a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'How can I become mor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
