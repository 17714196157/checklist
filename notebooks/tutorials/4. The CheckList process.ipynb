{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the [paper](https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf), you know that CheckList is more than this package, it's also a process.  \n",
    "This tutorial is a short version of that process, but you should really read the paper if you haven't :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Model: QQP, BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we'll use Quora Question Pair as an example, and I'm running a finetuned BERT model in a server.  \n",
    "The details below are not important, but are necessary for me to run the rest of the notebook. You won't be able to run them, but you can substitute your own model here if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "import sys\n",
    "import spacy\n",
    "import numpy as np\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import model_wrapper\n",
    "model = model_wrapper.ModelWrapper()\n",
    "new_pp = PredictorWrapper.wrap_softmax(model.predict_proba)\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\tWhat does the Quran say about homosexuality?\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qs = []\n",
    "labels = []\n",
    "all_questions = set()\n",
    "for x in open('/home/marcotcr/datasets/glue/glue_data/QQP/dev.tsv').readlines()[1:]:\n",
    "    try:\n",
    "        q1, q2, label = x.strip().split('\\t')[3:]\n",
    "    except:\n",
    "        print(x)\n",
    "        continue\n",
    "    all_questions.add(q1)\n",
    "    all_questions.add(q2)\n",
    "    qs.append((q1, q2))\n",
    "    labels.append(label)\n",
    "labels = np.array(labels).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset preprocessed by spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-627ddfa5ae0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspacy_map\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/marcotcr/tmp/processed_qqp.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mparsed_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacy_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.unpickle_doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.from_bytes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.from_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag_id\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.lemmatize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/checklist/lib/python3.6/site-packages/spacy/lemmatizer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string, univ_pos, morphology)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# See Issue #435 for example of where this logic is requied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_base_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniv_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmorphology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mindex_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lemma_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/checklist/lib/python3.6/site-packages/spacy/lemmatizer.py\u001b[0m in \u001b[0;36mis_base_form\u001b[0;34m(self, univ_pos, morphology)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mUniversal\u001b[0m \u001b[0mDependencies\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmorphology\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mmorphology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muniv_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"noun\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_qqp.pkl', 'rb'))\n",
    "parsed_qs = [(spacy_map[q[0]], spacy_map[q[1]]) for q in qs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-Down approach: the CheckList matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capabilities x Test Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutorial #3, we talked about specific test types.  \n",
    "In order to guide test ideation, it's useful to think of CheckList as a matrix of Capabilities x Test Types.  \n",
    "*Capabilities* refers to general-purpose linguistic capabilities, which manifest in one way or another in almost any NLP application.   \n",
    "We suggest that anyone CheckListing a model go through *at least* the following capabilities, trying to create MFTs, INVs, and DIRs for each if possible.\n",
    "1. **Vocabulary + POS:** important words or groups of words (by part-of-speech) for the task\n",
    "2. **Taxonomy**: synonyms, antonyms, word categories, etc\n",
    "3. **Robustness**: to typos, irrelevant additions, contractions, etc\n",
    "4. **Named Entity Recognition (NER)**: person names, locations, numbers, etc\n",
    "5. **Fairness**\n",
    "6. **Temporal understanding**: understanding order of events and how they impact the task\n",
    "7. **Negation**\n",
    "8. **Coreference** \n",
    "9. **Semantic Role Labeling (SRL)**: understanding roles such as agent, object, passive/active, etc\n",
    "10. **Logic**: symmetry, consistency, conjunctions, disjunctions, etc\n",
    "\n",
    "Notice that we are framing this as very top-down approach: you start with a list of capabilities and try to think of what kinds of tests can be created. We'll talk about how to incorporate some bottom-up thinking later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't try to create tests for **all** of these capabilities (but we do have notebooks with tests for all of them in the repo), just one as an example. \n",
    "Anyway, let's create a test suite (used to aggregate tests and save them for later use):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the NER capability.  \n",
    "How do named entities impact duplicate question detection? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFT\n",
    "It seems that the model should at least be able to distinguish questions about different people as non-duplicates.   \n",
    "Let's write an MFT where we have two people that have the same last name, but different first names.  \n",
    "Instead of running the test now, we'll add it to the suite and run all tests later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template((\n",
    "    'Is {first_name} {last_name} {mask}?',\n",
    "    'Is {first_name2} {last_name} {mask}?',\n",
    "    ),\n",
    "#     adj=adjs_without_overlap,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "test = MFT(**t, labels=0, name='same adjectives, different people', capability = 'NER',\n",
    "          description='Different first name, same adjective and last name')\n",
    "# test.run(new_pp)\n",
    "# test.summary(n=5)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INV\n",
    "If you have two questions with the same named entity, changing the entity on both should not change whether the questions are duplicates or not.  \n",
    "Let's write an INV for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with pairs of questions, we have to write a wrapper to make sure the same name is changed on both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_both(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    # separating out examples and meta. Meta has tuples (a, b), where name 'a' was changed to 'b'\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    # Only include examples where the same name was changed on both questions\n",
    "    return [(q1, q2) for q1, q2, m1, m2 in zip(c1, c2, m1, m2) if m1 == m2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_both, nsamples=200)\n",
    "test = INV(**t, name='Change same name in both questions', capability='NER',\n",
    "          description='')\n",
    "# test.run(new_pp)\n",
    "# test.summary(3)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIR\n",
    "Conversely, if an entity is present on a pair the model predicts as a duplicate and we change it to something else on *only one* of the sentences, the prediction should change to non-duplicate.  \n",
    "Let's write this as a DIR test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_on_one(qs):\n",
    "    q1, q2 = qs\n",
    "    c1 = Perturb.change_names(q1, seed=1, meta=True)\n",
    "    c2 = Perturb.change_names(q2, seed=1, meta=True)\n",
    "    if not c1 or not c2:\n",
    "        return\n",
    "    c1, m1 = c1\n",
    "    c2, m2 = c2\n",
    "    ret = []\n",
    "    ret.extend([(q1_, str(q2)) for q1_, m1_ in zip(c1, m1) if m1_[0] in str(q2)])\n",
    "    ret.extend([(str(q1), q2_) for q2_, m2_ in zip(c2, m2) if m2_[0] in str(q1)])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write an expectation function in two steps.  \n",
    "First, we want the prediction to be 0.  \n",
    "Second, we only want to include examples where the original prediction is one. We do this with a slice wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_fn = Expect.eq(0)\n",
    "expect_fn = Expect.slice_orig(expect_fn, lambda orig, *args: orig == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together into a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_name_on_one, nsamples=200)\n",
    "name = 'Change name in one of the questions'\n",
    "desc = 'Take pairs that are originally predicted as duplicates, change name in one of them and expect new prediction to be non-duplicate'\n",
    "test = DIR(**t, expect=expect_fn, name=name, description=desc, capability='NER')\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples illustrate how thinking through the matrix can help test ideation. We now turn to a bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we look at specific examples (from the validation dataset or elsewhere) and try to generalize them into MFTs, INVs or DIRs, placing them into a specific capability.  \n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(14)\n",
    "i = np.random.choice(len(qs))\n",
    "qs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example, in which a question asks about a comparison between two options, while the other question asks about a single option.  \n",
    "While they are not duplicates, it is possible that models would get confused here. I think this test fits into the Vocabulary+POS capability (it's not crucial for us to be completely precise about where a test fits).  \n",
    "Let's try to create an MFT out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(editor.suggest('{mask} is a large tech company.')[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['Apple', 'Google', 'Facebook', 'Microsoft', 'Amazon', 'Uber', 'Intel', 'Samsung', 'Netflix', 'Tesla', 'LinkedIn', 'Oracle', 'Target', 'Snap', 'Disney', 'AMD', 'Sony', 'Reddit', 'Youtube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(editor.suggest('Should I join {company} as a {mask}?', company=companies)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = ['developer', 'contributor', 'freshman', 'college grad', 'volunteer', 'writer', 'contractor', 'consultant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Which company should I join as a contractor, Youtube or Sony?',\n",
       "  'Should I join Youtube as a contractor?'),\n",
       " ('Which company should I join as a contributor, Snap or Disney?',\n",
       "  'Should I join Snap as a contributor?'),\n",
       " ('Which company should I join as a freshman, Google or Snap?',\n",
       "  'Should I join Google as a freshman?')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = editor.template((\n",
    "       'Which company should I join as a {role}, {company1} or {company2}?',\n",
    "       'Should I join {company1} as a {role}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    role=role,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=100,\n",
    ")\n",
    "t.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replicated the original example, but we can generalize it a bit to other comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('efforts', 'succeed'), ('strategy', 'work'), ('dominance', 'continue'), ('efforts', 'work'), ('plan', 'work'), ('strategy', 'working'), ('dominance', 'end'), ('experiment', 'work'), ('attempts', 'succeed'), ('approach', 'work'), ('success', 'continue'), ('tactics', 'work'), ('strategy', 'succeed'), ('experiment', 'succeed'), ('strategy', 'stick'), ('gamble', 'succeed'), ('gamble', 'work'), ('strategy', 'continue'), ('dominance', 'last'), ('strategy', 'worked'), ('dominance', 'sustainable'), ('crackdown', 'work'), ('plans', 'work'), ('efforts', 'continue'), ('decision', 'stick'), ('plan', 'succeed'), ('growth', 'continue'), ('experiments', 'work'), ('decision', 'stand'), ('strategy', 'change'), ('effort', 'succeed'), ('efforts', 'working'), ('attempts', 'work'), ('domination', 'continue'), ('move', 'work'), ('strategies', 'work'), ('lawsuit', 'succeed'), ('efforts', 'successful'), ('methods', 'work'), ('policies', 'change'), ('dominance', 'over'), ('strategy', 'stuck'), ('focus', 'change'), ('ambitions', 'succeed'), ('future', 'lie'), ('plans', 'succeed'), ('intentions', 'change'), ('success', 'sustainable'), ('strategy', 'fail'), ('ban', 'stand')\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join([str(x) for x in editor.suggest('Will Google\\'s {mask} {mask}?')][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Which company's CEO will quit later, Netflix or Sony?\",\n",
       "  \"Will Netflix's CEO quit?\"),\n",
       " (\"Which company's plan will work sooner, Disney or Sony?\",\n",
       "  \"Will Disney's plan work?\"),\n",
       " (\"Which company's effort will succeed most, Youtube or LinkedIn?\",\n",
       "  \"Will Youtube's effort succeed?\")]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t += editor.template((\n",
    "       'Which company\\'s {fverb[0]} will {fverb[1]} {comp}, {company1} or {company2}?',\n",
    "       'Will {company1}\\'s {fverb[0]} {fverb[1]}?',\n",
    "   ),\n",
    "    company=companies,\n",
    "    comp=['most', 'least', 'sooner', 'later'],\n",
    "    fverb=[('stock', 'rise'), ('CEO', 'quit'), ('board', 'resign'), ('stock', 'fall'), ('effort', 'succeed'), ('strategy', 'work'), ('plan', 'work'), ('gamble', 'work'), ('focus', 'change'), ('intentions', 'change')],\n",
    "    nsamples=300,\n",
    "    remove_duplicates=True,\n",
    ")\n",
    "t.data[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MFT(**t, labels=0, name='Comparison between two entities is not the same as asking about one', capability = 'Vocabulary',\n",
    "          description='')\n",
    "suite.add(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the suite, seeing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running How can I become more {synonym}?\n",
      "Predicting 200 examples\n",
      "Running How can I become more X = How can I become less antonym(X)\n",
      "Predicting 600 examples\n",
      "Running same adjectives, different people\n",
      "Predicting 296 examples\n",
      "Running Change same name in both questions\n",
      "Predicting 2034 examples\n",
      "Running Change name in one of the questions\n",
      "Predicting 3861 examples\n",
      "Running Comparison between two entities is not the same as asking about one\n",
      "Predicting 378 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(new_pp, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Comparison between two entities is not the same as asking about one\n",
      "Test cases:      378\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taxonomy\n",
      "\n",
      "How can I become more {synonym}?\n",
      "Test cases:      200\n",
      "Fails (rate):    40 (20.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 ('How can I become more happy?', 'How can I become more joyful?')\n",
      "----\n",
      "0.3 ('How can I become more spiritual?', 'How can I become more religious?')\n",
      "----\n",
      "0.3 ('How can I become more spiritual?', 'How can I become more religious?')\n",
      "----\n",
      "\n",
      "\n",
      "How can I become more X = How can I become less antonym(X)\n",
      "Test cases:      600\n",
      "Fails (rate):    405 (67.5%)\n",
      "\n",
      "Example fails:\n",
      "0.0 ('How can I become less impatient?', 'How can I become more patient?')\n",
      "----\n",
      "0.3 ('How can I become less irresponsible?', 'How can I become more responsible?')\n",
      "----\n",
      "0.0 ('How can I become less impatient?', 'How can I become more patient?')\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "same adjectives, different people\n",
      "Test cases:      296\n",
      "Fails (rate):    27 (9.1%)\n",
      "\n",
      "Example fails:\n",
      "0.7 ('Is Anthony Taylor Muslim?', 'Is Michael Taylor Muslim?')\n",
      "----\n",
      "0.9 ('Is Matthew Campbell True?', 'Is Jason Campbell True?')\n",
      "----\n",
      "0.8 ('Is Taylor Turner Transgender?', 'Is Erin Turner Transgender?')\n",
      "----\n",
      "\n",
      "\n",
      "Change same name in both questions\n",
      "Test cases:      200\n",
      "Fails (rate):    25 (12.5%)\n",
      "\n",
      "Example fails:\n",
      "0.9 ('Is the word pussy no longer on the list of forbidden words? Do we have Donald Trump to thank for this?', 'Is the word p#ssy no longer on the list of forbidden words? Do we have Donald Trump to thank for this?')\n",
      "0.4 ('Is the word pussy no longer on the list of forbidden words? Do we have David Lewis to thank for this?', 'Is the word p#ssy no longer on the list of forbidden words? Do we have David Lewis to thank for this?')\n",
      "\n",
      "----\n",
      "0.8 ('How many times has Donald Trump gone bankrupt and did he use loopholes to build his business(es) back up?', 'In the last 20 years, how many failed businesses has Donald Trump had? How many times has he filed bankruptcy?')\n",
      "0.3 ('How many times has Michael Brooks gone bankrupt and did he use loopholes to build his business(es) back up?', 'In the last 20 years, how many failed businesses has Michael Brooks had? How many times has he filed bankruptcy?')\n",
      "\n",
      "----\n",
      "0.0 ('Why do people say that Ronaldo is better than Messi?', 'Who is better as a person, Ronaldo or Messi?')\n",
      "0.8 ('Why do people say that Nicholas is better than Messi?', 'Who is better as a person, Nicholas or Messi?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change name in one of the questions\n",
      "Test cases:      200\n",
      "Fails (rate):    40 (20.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Donald Trump in the 2016 Presidential election?')\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Daniel Smith in the 2016 Presidential election?')\n",
      "1.0 ('Would Bernie Sanders have defeated Donald Trump?', 'How valid is the notion that Bernie Sanders might have defeated Joshua Johnson in the 2016 Presidential election?')\n",
      "\n",
      "----\n",
      "1.0 ('Why do you think 50% of people voted for slightly racist Donald Trump against Ted and Rubio in the Primary?', 'Why do you think 50% of people voted for racist Donald Trump?')\n",
      "0.9 ('Why do you think 50% of people voted for slightly racist Donald Trump against Ted and Rubio in the Primary?', 'Why do you think 50% of people voted for racist John Lopez?')\n",
      "0.7 ('Why do you think 50% of people voted for slightly racist John Lopez against Ted and Rubio in the Primary?', 'Why do you think 50% of people voted for racist Donald Trump?')\n",
      "\n",
      "----\n",
      "1.0 (\"Why aren't supporters of Bernie Sanders voting for Jill Stein?\", 'Why don’t Bernie supporters vote for Jill Stein?')\n",
      "0.6 (\"Why aren't supporters of Bernie Sanders voting for Emily Parker?\", 'Why don’t Bernie supporters vote for Jill Stein?')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84dc19ac4ca40a2a3433315d65a388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'How can I become mor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: testing Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's create a few addi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.synonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        tmp.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(', '.join([str(tuple(x)) for x in tmp][:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of those, let's pick a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can create a simple MFT, where we expect the model to recognize these synonyms.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    (\n",
    "    'How can I become {moreless} {x[0]}?',\n",
    "    'How can I become {moreless} {x[1]}?',\n",
    "    ),\n",
    "    x=synonyms,\n",
    "    moreless=['more', 'less'],\n",
    "    remove_duplicates=True, \n",
    "    nsamples=200)\n",
    "name = 'How can I become more {synonym}?' \n",
    "desc = 'different (simple) templates where words are replaced with their synonyms'\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with antonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opps = []\n",
    "x = editor.suggest('How can I become more {mask}?')\n",
    "x += editor.suggest('How can I become less {mask}?')\n",
    "for a in set(x):\n",
    "    e = editor.antonyms('How can I become {moreless} %s?' % a, a, moreless=['more', 'less'])\n",
    "    if e:\n",
    "#         print(a, [b[0][0] for b in e] )\n",
    "        opps.append([a] + e)\n",
    "#         opps.append((a, e[0][0][0]))\n",
    "print(','.join([str(tuple(x)) for x in opps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template([(\n",
    "    'How can I become more {x[0]}?',\n",
    "    'How can I become less {x[1]}?',\n",
    "    ),\n",
    "    (\n",
    "    'How can I become less {x[0]}?',\n",
    "    'How can I become more {x[1]}?',\n",
    "    )],\n",
    "    unroll=True,\n",
    "    x=antonyms,\n",
    "    remove_duplicates=True, \n",
    "    nsamples=300)\n",
    "name = 'How can I become more X = How can I become less antonym(X)' \n",
    "desc = ''\n",
    "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
    "          description=desc)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be easy to turn the synonym one into an INV as well (we do this in another notebook), but let's turn to another capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.visual_summary_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checklist",
   "language": "python",
   "name": "checklist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
